{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f46298e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:32:40.153394Z",
     "iopub.status.busy": "2024-10-11T21:32:40.152524Z",
     "iopub.status.idle": "2024-10-11T21:32:57.604819Z",
     "shell.execute_reply": "2024-10-11T21:32:57.603392Z"
    },
    "papermill": {
     "duration": 17.465059,
     "end_time": "2024-10-11T21:32:57.607511",
     "exception": false,
     "start_time": "2024-10-11T21:32:40.142452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# installing the libraries for transformers\n",
    "#!pip install -U -q sentence-transformers transformers bitsandbytes accelerate sentencepiece\n",
    "\n",
    "# install libarary to convert latex to text\n",
    "#!pip install -U pylatexenc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03395fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:16:36 - INFO - starting script\n"
     ]
    }
   ],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logging.info(\"starting script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d24f104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\billl\\AppData\\Local\\Temp\\ipykernel_6740\\354891771.py:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  \"\"\" # test tokenize latex\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' # test tokenize latex\\nfrom transformers import AlbertTokenizer\\nimport torch\\n\\n# Load the tokenizer\\ntokenizer = AlbertTokenizer.from_pretrained(\\'albert-base-v2\\')\\n\\n# Example LaTeX math expressions\\nlatex_expressions = [\\n    r\"\\x0crac{a}{b}\",\\n    r\"\\\\int_0^{\\\\infty} e^{-x^2} dx\",\\n    r\"E = mc^2\"\\n]\\n\\n# Tokenize the LaTeX expressions\\ntokens = tokenizer(latex_expressions, padding=True, truncation=True, return_tensors=\"pt\")\\n\\n# Print tokenized input\\nprint(tokens.input_ids)\\n '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # test tokenize latex\n",
    "from transformers import AlbertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "# Example LaTeX math expressions\n",
    "latex_expressions = [\n",
    "    r\"\\frac{a}{b}\",\n",
    "    r\"\\int_0^{\\infty} e^{-x^2} dx\",\n",
    "    r\"E = mc^2\"\n",
    "]\n",
    "\n",
    "# Tokenize the LaTeX expressions\n",
    "tokens = tokenizer(latex_expressions, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Print tokenized input\n",
    "print(tokens.input_ids)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6b4fb81",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-11T21:32:57.621236Z",
     "iopub.status.busy": "2024-10-11T21:32:57.620241Z",
     "iopub.status.idle": "2024-10-11T21:33:03.549233Z",
     "shell.execute_reply": "2024-10-11T21:33:03.547837Z"
    },
    "papermill": {
     "duration": 5.938697,
     "end_time": "2024-10-11T21:33:03.552021",
     "exception": false,
     "start_time": "2024-10-11T21:32:57.613324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Deep Learning library\n",
    "import torch\n",
    "\n",
    "# to load transformer models\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "#from transformers import T5Tokenizer, T5ForConditionalGeneration, pipeline # T5 is Google\n",
    "\n",
    "# to split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to compute performance metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78fa8816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.565014Z",
     "iopub.status.busy": "2024-10-11T21:33:03.564479Z",
     "iopub.status.idle": "2024-10-11T21:33:03.572812Z",
     "shell.execute_reply": "2024-10-11T21:33:03.571462Z"
    },
    "papermill": {
     "duration": 0.017682,
     "end_time": "2024-10-11T21:33:03.575387",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.557705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['misconception_mapping.csv', 'sample_submission.csv', 'test.csv', 'train.csv']\n",
      "./eedi-mining/eedi-mining-misconceptions-in-mathematics\\misconception_mapping.csv\n",
      "./eedi-mining/eedi-mining-misconceptions-in-mathematics\\sample_submission.csv\n",
      "./eedi-mining/eedi-mining-misconceptions-in-mathematics\\test.csv\n",
      "./eedi-mining/eedi-mining-misconceptions-in-mathematics\\train.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "files = []\n",
    "# on vs code\n",
    "data_dir = './eedi-mining/eedi-mining-misconceptions-in-mathematics'\n",
    "miscon_file_index = 0\n",
    "train_file_index = 3\n",
    "test_file_index = 2\n",
    "# on kaggle\n",
    "# data_dir = '/kaggle/input'\n",
    "#miscon_file_index = 1\n",
    "#train_file_index = 2\n",
    "#test_file_index = 3\n",
    "for dirname, _, filenames in os.walk(data_dir):\n",
    "    print (filenames)\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        files.append(os.path.join(dirname, filename))\n",
    "misconceptions_filename = files[miscon_file_index]\n",
    "train_filename = files[train_file_index]\n",
    "test_filename = files[test_file_index]\n",
    "# For Kaggle, You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91933dd3",
   "metadata": {
    "papermill": {
     "duration": 0.005348,
     "end_time": "2024-10-11T21:33:03.586369",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.581021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## File and Field Information\n",
    "### [train/test].csv\n",
    "\n",
    "* QuestionId - Unique question identifier (int).\n",
    "* ConstructId - Unique construct identifier (int) .\n",
    "* ConstructName - Most granular level of knowledge related to question (str).\n",
    "* CorrectAnswer - A, B, C or D (char).\n",
    "* SubjectId - Unique subject identifier (int).\n",
    "* SubjectName - More general context than the construct (str).\n",
    "* QuestionText - Question text extracted from the question image using human-in-the-loop OCR (str) .\n",
    "* Answer[A/B/C/D]Text - Answer option A text extracted from the question image using human-in-the-loop OCR (str).\n",
    "* Misconception[A/B/C/D]Id - Unique misconception identifier (int). Ground truth labels in train.csv; your task is to predict these labels for test.csv.\n",
    "\n",
    "### misconception_mapping.csv\n",
    "maps MisconceptionId to its MisconceptionName\n",
    "\n",
    "### sample_submission.csv\n",
    "A submission file in the correct format.\n",
    "* QuestionId_Answer - Each question has three incorrect answers for which need you predict the MisconceptionId.\n",
    "* MisconceptionId - You can predict up to 25 values, space delimited."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa158d76",
   "metadata": {},
   "source": [
    "# get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da4619fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.599250Z",
     "iopub.status.busy": "2024-10-11T21:33:03.598838Z",
     "iopub.status.idle": "2024-10-11T21:33:03.674388Z",
     "shell.execute_reply": "2024-10-11T21:33:03.673179Z"
    },
    "papermill": {
     "duration": 0.085241,
     "end_time": "2024-10-11T21:33:03.677012",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.591771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>AnswerAText</th>\n",
       "      <th>AnswerBText</th>\n",
       "      <th>AnswerCText</th>\n",
       "      <th>AnswerDText</th>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <th>MisconceptionDId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>\\( 3 \\times 2+(4-5) \\)</td>\n",
       "      <td>\\( 3 \\times(2+4-5) \\)</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1612</td>\n",
       "      <td>Simplify an algebraic fraction by factorising ...</td>\n",
       "      <td>1077</td>\n",
       "      <td>Simplifying Algebraic Fractions</td>\n",
       "      <td>D</td>\n",
       "      <td>Simplify the following, if possible: \\( \\frac{...</td>\n",
       "      <td>\\( m+1 \\)</td>\n",
       "      <td>\\( m+2 \\)</td>\n",
       "      <td>\\( m-1 \\)</td>\n",
       "      <td>Does not simplify</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2774</td>\n",
       "      <td>Calculate the range from a list of data</td>\n",
       "      <td>339</td>\n",
       "      <td>Range and Interquartile Range from a List of Data</td>\n",
       "      <td>B</td>\n",
       "      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n",
       "      <td>Only\\nTom</td>\n",
       "      <td>Only\\nKatie</td>\n",
       "      <td>Both Tom and Katie</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>1073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2377</td>\n",
       "      <td>Recall and use the intersecting diagonals prop...</td>\n",
       "      <td>88</td>\n",
       "      <td>Properties of Quadrilaterals</td>\n",
       "      <td>C</td>\n",
       "      <td>The angles highlighted on this rectangle with ...</td>\n",
       "      <td>acute</td>\n",
       "      <td>obtuse</td>\n",
       "      <td>\\( 90^{\\circ} \\)</td>\n",
       "      <td>Not enough information</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3387</td>\n",
       "      <td>Substitute positive integer values into formul...</td>\n",
       "      <td>67</td>\n",
       "      <td>Substitution into Formula</td>\n",
       "      <td>A</td>\n",
       "      <td>The equation \\( f=3 r^{2}+3 \\) is used to find...</td>\n",
       "      <td>\\( 30 \\)</td>\n",
       "      <td>\\( 27 \\)</td>\n",
       "      <td>\\( 51 \\)</td>\n",
       "      <td>\\( 24 \\)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1818.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  ConstructId                                      ConstructName  \\\n",
       "0           0          856  Use the order of operations to carry out calcu...   \n",
       "1           1         1612  Simplify an algebraic fraction by factorising ...   \n",
       "2           2         2774            Calculate the range from a list of data   \n",
       "3           3         2377  Recall and use the intersecting diagonals prop...   \n",
       "4           4         3387  Substitute positive integer values into formul...   \n",
       "\n",
       "   SubjectId                                        SubjectName CorrectAnswer  \\\n",
       "0         33                                             BIDMAS             A   \n",
       "1       1077                    Simplifying Algebraic Fractions             D   \n",
       "2        339  Range and Interquartile Range from a List of Data             B   \n",
       "3         88                       Properties of Quadrilaterals             C   \n",
       "4         67                          Substitution into Formula             A   \n",
       "\n",
       "                                        QuestionText            AnswerAText  \\\n",
       "0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n",
       "1  Simplify the following, if possible: \\( \\frac{...              \\( m+1 \\)   \n",
       "2  Tom and Katie are discussing the \\( 5 \\) plant...              Only\\nTom   \n",
       "3  The angles highlighted on this rectangle with ...                  acute   \n",
       "4  The equation \\( f=3 r^{2}+3 \\) is used to find...               \\( 30 \\)   \n",
       "\n",
       "              AnswerBText            AnswerCText             AnswerDText  \\\n",
       "0  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)  Does not need brackets   \n",
       "1               \\( m+2 \\)              \\( m-1 \\)       Does not simplify   \n",
       "2             Only\\nKatie     Both Tom and Katie      Neither is correct   \n",
       "3                  obtuse       \\( 90^{\\circ} \\)  Not enough information   \n",
       "4                \\( 27 \\)               \\( 51 \\)                \\( 24 \\)   \n",
       "\n",
       "   MisconceptionAId  MisconceptionBId  MisconceptionCId  MisconceptionDId  \n",
       "0               NaN               NaN               NaN            1672.0  \n",
       "1            2142.0             143.0            2142.0               NaN  \n",
       "2            1287.0               NaN            1287.0            1073.0  \n",
       "3            1180.0            1180.0               NaN            1180.0  \n",
       "4               NaN               NaN               NaN            1818.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_filename)\n",
    "train_data_orig = train_data.copy()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e6d36e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.691466Z",
     "iopub.status.busy": "2024-10-11T21:33:03.691030Z",
     "iopub.status.idle": "2024-10-11T21:33:03.697465Z",
     "shell.execute_reply": "2024-10-11T21:33:03.696225Z"
    },
    "papermill": {
     "duration": 0.016504,
     "end_time": "2024-10-11T21:33:03.699689",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.683185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape\n",
      "rows 1869\n",
      "columns 15\n"
     ]
    }
   ],
   "source": [
    "print (\"train_data shape\")\n",
    "print(\"rows\",train_data.shape[0])\n",
    "print(\"columns\",train_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af197cc",
   "metadata": {},
   "source": [
    "## Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78a60534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data shape\n",
      "rows 3\n",
      "columns 11\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_filename)\n",
    "test_data_orig = test_data.copy()\n",
    "test_data.head()\n",
    "print (\"test_data shape\")\n",
    "print(\"rows\", test_data.shape[0])\n",
    "print(\"columns\",test_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a6c2c3",
   "metadata": {},
   "source": [
    "## Get misconception data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea7fc5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miscon_data shape\n",
      "rows 2587\n",
      "columns 2\n"
     ]
    }
   ],
   "source": [
    "miscon_data = pd.read_csv(misconceptions_filename)\n",
    "miscon_data.head()\n",
    "print (\"miscon_data shape\")\n",
    "print(\"rows\", miscon_data.shape[0])\n",
    "print(\"columns\",miscon_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43fec04c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.713457Z",
     "iopub.status.busy": "2024-10-11T21:33:03.713053Z",
     "iopub.status.idle": "2024-10-11T21:33:03.748166Z",
     "shell.execute_reply": "2024-10-11T21:33:03.747082Z"
    },
    "papermill": {
     "duration": 0.044582,
     "end_time": "2024-10-11T21:33:03.750510",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.705928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163  different subject groups\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>AnswerAText</th>\n",
       "      <th>AnswerBText</th>\n",
       "      <th>AnswerCText</th>\n",
       "      <th>AnswerDText</th>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <th>MisconceptionDId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>Linear Equations</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171</td>\n",
       "      <td>Linear Sequences (nth term)</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>Quadratic Equations</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>Area of Simple Shapes</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubjectId                  SubjectName  QuestionId  ConstructId  \\\n",
       "0         64             Linear Equations          53           53   \n",
       "1        171  Linear Sequences (nth term)          44           44   \n",
       "2         33                       BIDMAS          37           37   \n",
       "3         65          Quadratic Equations          36           36   \n",
       "4         75        Area of Simple Shapes          36           36   \n",
       "\n",
       "   ConstructName  CorrectAnswer  QuestionText  AnswerAText  AnswerBText  \\\n",
       "0             53             53            53           53           53   \n",
       "1             44             44            44           44           44   \n",
       "2             37             37            37           37           37   \n",
       "3             36             36            36           36           36   \n",
       "4             36             36            36           36           36   \n",
       "\n",
       "   AnswerCText  AnswerDText  MisconceptionAId  MisconceptionBId  \\\n",
       "0           53           53                23                32   \n",
       "1           44           44                28                20   \n",
       "2           37           37                20                21   \n",
       "3           36           36                18                17   \n",
       "4           36           36                22                26   \n",
       "\n",
       "   MisconceptionCId  MisconceptionDId  \n",
       "0                30                27  \n",
       "1                21                19  \n",
       "2                23                24  \n",
       "3                25                14  \n",
       "4                23                24  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_groups = train_data.groupby([\"SubjectId\",\"SubjectName\"]).count().sort_values('QuestionId',ascending=False).reset_index()\n",
    "print(subject_groups.shape[0], \" different subject groups\")\n",
    "subject_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37911c24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.764474Z",
     "iopub.status.busy": "2024-10-11T21:33:03.764077Z",
     "iopub.status.idle": "2024-10-11T21:33:03.784796Z",
     "shell.execute_reply": "2024-10-11T21:33:03.783750Z"
    },
    "papermill": {
     "duration": 0.03045,
     "end_time": "2024-10-11T21:33:03.787167",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.756717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentages of null values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <td>734</td>\n",
       "      <td>39.272338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <td>751</td>\n",
       "      <td>40.181915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <td>789</td>\n",
       "      <td>42.215088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MisconceptionDId</th>\n",
       "      <td>832</td>\n",
       "      <td>44.515784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count  Percentage\n",
       "MisconceptionAId    734   39.272338\n",
       "MisconceptionBId    751   40.181915\n",
       "MisconceptionCId    789   42.215088\n",
       "MisconceptionDId    832   44.515784"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"percentages of null values\")\n",
    "pd.DataFrame({'Count':train_data.isnull().sum()[train_data.isnull().sum()>0],'Percentage':(train_data.isnull().sum()[train_data.isnull().sum()>0]/train_data.shape[0])*100})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7dfc4",
   "metadata": {
    "papermill": {
     "duration": 0.006399,
     "end_time": "2024-10-11T21:33:03.800248",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.793849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Clean up missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39ae2fd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.814857Z",
     "iopub.status.busy": "2024-10-11T21:33:03.814474Z",
     "iopub.status.idle": "2024-10-11T21:33:03.826219Z",
     "shell.execute_reply": "2024-10-11T21:33:03.825074Z"
    },
    "papermill": {
     "duration": 0.021905,
     "end_time": "2024-10-11T21:33:03.828723",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.806818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(482, 15)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# records where more than one misconception id is missing\n",
    "missing_a_misconception = train_data[(train_data.CorrectAnswer == \"A\") & (train_data.MisconceptionBId.isnull() | train_data.MisconceptionCId.isnull()  | train_data.MisconceptionDId.isnull()) ]\n",
    "print(missing_a_misconception.shape)\n",
    "missing_a_misconception.head()\n",
    "train_data[(train_data.CorrectAnswer == \"A\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e0a88b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.844101Z",
     "iopub.status.busy": "2024-10-11T21:33:03.843134Z",
     "iopub.status.idle": "2024-10-11T21:33:03.863713Z",
     "shell.execute_reply": "2024-10-11T21:33:03.862490Z"
    },
    "papermill": {
     "duration": 0.030708,
     "end_time": "2024-10-11T21:33:03.866058",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.835350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>AnswerAText</th>\n",
       "      <th>AnswerBText</th>\n",
       "      <th>AnswerCText</th>\n",
       "      <th>AnswerDText</th>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <th>MisconceptionDId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1414</td>\n",
       "      <td>Expand products of three binomials in the form...</td>\n",
       "      <td>335</td>\n",
       "      <td>Expanding Triple Brackets and more</td>\n",
       "      <td>B</td>\n",
       "      <td>John is expanding these three brackets:\\n\\(\\n(...</td>\n",
       "      <td>\\( +6 x^{2} \\)</td>\n",
       "      <td>\\( \\begin{array}{l}+6 x^{2} \\\\ -3 x^{2} \\\\ +5 ...</td>\n",
       "      <td>\\( \\begin{array}{l}+6 x^{2} \\\\ +3 x^{2} \\\\ +5 ...</td>\n",
       "      <td>\\( \\begin{array}{l}+6 x^{2} \\\\ -3 x^{2} \\\\ -5 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>583.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>3065</td>\n",
       "      <td>Convert from hours to minutes</td>\n",
       "      <td>209</td>\n",
       "      <td>Time</td>\n",
       "      <td>B</td>\n",
       "      <td>Hannah's journey to camp is \\( 3 \\) hours and ...</td>\n",
       "      <td>\\( 196 \\) minutes</td>\n",
       "      <td>\\( 18 \\) minutes</td>\n",
       "      <td>\\( 102 \\) minutes</td>\n",
       "      <td>\\( 12 \\) minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>261</td>\n",
       "      <td>Carry out missing number subtraction problems ...</td>\n",
       "      <td>211</td>\n",
       "      <td>Adding and Subtracting Negative Numbers</td>\n",
       "      <td>B</td>\n",
       "      <td>![Number line with -12 and -7 marked. Starting...</td>\n",
       "      <td>\\( -7 \\)</td>\n",
       "      <td>\\( -5 \\)</td>\n",
       "      <td>\\( -2 \\)</td>\n",
       "      <td>\\( -6 \\)</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1824.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2306</td>\n",
       "      <td>Given the volume of a cuboid, work out missing...</td>\n",
       "      <td>189</td>\n",
       "      <td>Volume of Prisms</td>\n",
       "      <td>B</td>\n",
       "      <td>The volume of this cuboid is \\( 30 \\mathrm{~cm...</td>\n",
       "      <td>\\( 6 \\mathrm{~cm} \\)</td>\n",
       "      <td>\\( 5 \\mathrm{~cm} \\)</td>\n",
       "      <td>\\( 4 \\mathrm{~cm} \\)</td>\n",
       "      <td>\\( 25 \\mathrm{~cm} \\)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1434</td>\n",
       "      <td>Factorise a quadratic expression in the form a...</td>\n",
       "      <td>53</td>\n",
       "      <td>Factorising into a Double Bracket</td>\n",
       "      <td>B</td>\n",
       "      <td>Step 1: Factorise the following expression\\n\\n...</td>\n",
       "      <td>\\( (3 x+2)(3 x+1) \\)</td>\n",
       "      <td>\\( (3 x+2)(x+1) \\)</td>\n",
       "      <td>Cannot be factorised</td>\n",
       "      <td>\\( (3 x+1)(x+2) \\)</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    QuestionId  ConstructId  \\\n",
       "10          10         1414   \n",
       "13          13         3065   \n",
       "18          18          261   \n",
       "20          20         2306   \n",
       "21          21         1434   \n",
       "\n",
       "                                        ConstructName  SubjectId  \\\n",
       "10  Expand products of three binomials in the form...        335   \n",
       "13                      Convert from hours to minutes        209   \n",
       "18  Carry out missing number subtraction problems ...        211   \n",
       "20  Given the volume of a cuboid, work out missing...        189   \n",
       "21  Factorise a quadratic expression in the form a...         53   \n",
       "\n",
       "                                SubjectName CorrectAnswer  \\\n",
       "10       Expanding Triple Brackets and more             B   \n",
       "13                                     Time             B   \n",
       "18  Adding and Subtracting Negative Numbers             B   \n",
       "20                         Volume of Prisms             B   \n",
       "21        Factorising into a Double Bracket             B   \n",
       "\n",
       "                                         QuestionText           AnswerAText  \\\n",
       "10  John is expanding these three brackets:\\n\\(\\n(...        \\( +6 x^{2} \\)   \n",
       "13  Hannah's journey to camp is \\( 3 \\) hours and ...     \\( 196 \\) minutes   \n",
       "18  ![Number line with -12 and -7 marked. Starting...              \\( -7 \\)   \n",
       "20  The volume of this cuboid is \\( 30 \\mathrm{~cm...  \\( 6 \\mathrm{~cm} \\)   \n",
       "21  Step 1: Factorise the following expression\\n\\n...  \\( (3 x+2)(3 x+1) \\)   \n",
       "\n",
       "                                          AnswerBText  \\\n",
       "10  \\( \\begin{array}{l}+6 x^{2} \\\\ -3 x^{2} \\\\ +5 ...   \n",
       "13                                   \\( 18 \\) minutes   \n",
       "18                                           \\( -5 \\)   \n",
       "20                               \\( 5 \\mathrm{~cm} \\)   \n",
       "21                                 \\( (3 x+2)(x+1) \\)   \n",
       "\n",
       "                                          AnswerCText  \\\n",
       "10  \\( \\begin{array}{l}+6 x^{2} \\\\ +3 x^{2} \\\\ +5 ...   \n",
       "13                                  \\( 102 \\) minutes   \n",
       "18                                           \\( -2 \\)   \n",
       "20                               \\( 4 \\mathrm{~cm} \\)   \n",
       "21                               Cannot be factorised   \n",
       "\n",
       "                                          AnswerDText  MisconceptionAId  \\\n",
       "10  \\( \\begin{array}{l}+6 x^{2} \\\\ -3 x^{2} \\\\ -5 ...               NaN   \n",
       "13                                   \\( 12 \\) minutes               NaN   \n",
       "18                                           \\( -6 \\)            2179.0   \n",
       "20                              \\( 25 \\mathrm{~cm} \\)               NaN   \n",
       "21                                 \\( (3 x+1)(x+2) \\)            2240.0   \n",
       "\n",
       "    MisconceptionBId  MisconceptionCId  MisconceptionDId  \n",
       "10               NaN             583.0               NaN  \n",
       "13               NaN             161.0               NaN  \n",
       "18               NaN               NaN            1824.0  \n",
       "20               NaN               NaN            1984.0  \n",
       "21               NaN               NaN               NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_b_misconpception = train_data[(train_data.CorrectAnswer == \"B\") & (train_data.MisconceptionAId.isnull() | train_data.MisconceptionCId.isnull()) ]\n",
    "missing_b_misconpception.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "058c0c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.882489Z",
     "iopub.status.busy": "2024-10-11T21:33:03.881247Z",
     "iopub.status.idle": "2024-10-11T21:33:03.904981Z",
     "shell.execute_reply": "2024-10-11T21:33:03.903808Z"
    },
    "papermill": {
     "duration": 0.034228,
     "end_time": "2024-10-11T21:33:03.907447",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.873219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MisconceptionId</th>\n",
       "      <th>MisconceptionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Does not know that angles in a triangle sum to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Uses dividing fractions method for multiplying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Believes there are 100 degrees in a full turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Thinks a quadratic without a non variable term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Believes addition of terms and powers of terms...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MisconceptionId                                  MisconceptionName\n",
       "0                0  Does not know that angles in a triangle sum to...\n",
       "1                1  Uses dividing fractions method for multiplying...\n",
       "2                2      Believes there are 100 degrees in a full turn\n",
       "3                3  Thinks a quadratic without a non variable term...\n",
       "4                4  Believes addition of terms and powers of terms..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misc_con_data = pd.read_csv(misconceptions_filename)\n",
    "misc_con_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef1936",
   "metadata": {
    "papermill": {
     "duration": 0.006867,
     "end_time": "2024-10-11T21:33:03.921718",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.914851",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Update data to prepare for creating vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa7711df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.937762Z",
     "iopub.status.busy": "2024-10-11T21:33:03.937345Z",
     "iopub.status.idle": "2024-10-11T21:33:03.945991Z",
     "shell.execute_reply": "2024-10-11T21:33:03.945012Z"
    },
    "papermill": {
     "duration": 0.019362,
     "end_time": "2024-10-11T21:33:03.948203",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.928841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean up question\n",
    "# train_data['CleanQuestion'] = train_data['QuestionText'].replace('\\n',' ',regex=True)\n",
    "\n",
    "# create new data frame with just misconceptions\n",
    "# Create a new empty DataFrame\n",
    "miscon_model = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e3110a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:03.964356Z",
     "iopub.status.busy": "2024-10-11T21:33:03.963943Z",
     "iopub.status.idle": "2024-10-11T21:33:29.687826Z",
     "shell.execute_reply": "2024-10-11T21:33:29.686904Z"
    },
    "papermill": {
     "duration": 25.734764,
     "end_time": "2024-10-11T21:33:29.690238",
     "exception": false,
     "start_time": "2024-10-11T21:33:03.955474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:49: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:49: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\billl\\AppData\\Local\\Temp\\ipykernel_6740\\2774360719.py:49: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  text = \"Here's an example: \\int_0^{\\infty} e^{-x^2} dx.\\n Let's clean it up!\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heres an example \\int_0^{\\infty} e^{x^2} dx lets clean it up\n"
     ]
    }
   ],
   "source": [
    "# convert latext formatting to text\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "import pylatexenc\n",
    "# Convert LaTeX to plain text\n",
    "# Function to convert LaTeX to text\n",
    "def latex_to_text(latex_string):\n",
    "    return LatexNodes2Text().latex_to_text(latex_string)\n",
    "\n",
    "# repolace names with variables to get consistency on vectors\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "# for running locally, need to do\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to replace all detected names with unique variables\n",
    "def replace_names_with_variables(text):\n",
    "    doc = nlp(text)\n",
    "    name_counter = 1\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            var_name = f\"NAME{name_counter}\"\n",
    "            text = text.replace(ent.text, var_name)\n",
    "            name_counter += 1\n",
    "    return text\n",
    "\n",
    "#def clean_math_text(text):\n",
    "    # clean_text = latex_to_text(text)\n",
    "    # clean_text = replace_names_with_variables(clean_text)\n",
    "    # remove new line and other characters\n",
    "    # print('before',clean_text)\n",
    "    #clean_text = clean_text.replace('\\n',' ')\n",
    "    # print('after', clean_text)\n",
    "    \n",
    "    #return clean_text \n",
    "import re\n",
    "\n",
    "def clean_math_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters (keeping LaTeX symbols)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\\\{}^_]', '', text)\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Example text\n",
    "text = \"Here's an example: \\int_0^{\\infty} e^{-x^2} dx.\\n Let's clean it up!\"\n",
    "\n",
    "# Clean the text\n",
    "cleaned_text = clean_math_text(text)\n",
    "print(cleaned_text)\n",
    "\n",
    "\n",
    "# remove special characters like new line\n",
    "#miscon_model['subjectName'] = train_data.SubjectName\n",
    "#miscon_model['constructName'] = train_data.ConstructName\n",
    "#miscon_model['question'] = train_data['QuestionText'].apply(clean_math_text)\n",
    "#  Creating the flattened DataFrame\n",
    "import math\n",
    "flattened_data = []\n",
    "for index, row in train_data.iterrows():\n",
    "    # put incorrect answer A into row\n",
    "    # print (\"a id\",row.MisconceptionAId)\n",
    "\n",
    "    if ((row.CorrectAnswer != \"A\") & (math.isnan(row.MisconceptionAId) == False)):\n",
    "        misconception_text_row = miscon_data[(miscon_data.MisconceptionId==row.MisconceptionAId)]\n",
    "        misconception_id = row.MisconceptionAId\n",
    "        formatted_answer = clean_math_text(row['AnswerAText'])\n",
    "        # flattened_data.append({'subjectName': row['SubjectName'], 'constructName': row['ConstructName'], 'latex_formatted_question': row['QuestionText'], 'question': clean_math_text(row['QuestionText']), 'latex_formatted_wrongAnswer': row['AnswerAText'], 'wrongAnswer': clean_math_text(row['AnswerAText']), 'misconception': misconception_row.MisconceptionName})\n",
    "    if ((row.CorrectAnswer != \"B\") & (math.isnan(row.MisconceptionBId)==False)):\n",
    "        misconception_text_row = miscon_data[(miscon_data.MisconceptionId==row.MisconceptionBId)]\n",
    "        misconception_id = row.MisconceptionBId\n",
    "        formatted_answer= clean_math_text(row['AnswerBText'])\n",
    "        # flattened_data.append({'subjectName': row['SubjectName']}, 'constructName': row['ConstructName'], 'latex_formatted_question': row['QuestionText'], 'question': clean_math_text(row['QuestionText']), 'latext_formatted_wrongAnswer': row['AnswerBText'], 'wrongAnswer': clean_math_text(row['AnswerBText']), 'misconception': misconception_row.MisconceptionName})\n",
    "    if ((row.CorrectAnswer != \"C\") & (math.isnan(row.MisconceptionCId) ==False)):\n",
    "        misconception_text_row = miscon_data[(miscon_data.MisconceptionId==row.MisconceptionCId)]\n",
    "        misconception_id = row.MisconceptionCId\n",
    "        formatted_answer = clean_math_text(row['AnswerCText'])        \n",
    "        # flattened_data.append({'subjectName': row['SubjectName'], 'constructName': row['ConstructName'], 'latex_formatted_question': row['QuestionText'], 'question': clean_math_text(row['QuestionText']), 'latext_formatted_wrongAnswer': row['AnswerCText'], 'wrongAnswer': clean_math_text(row['AnswerCText']), 'misconception': misconception_row.MisconceptionName})\n",
    "    if ((row.CorrectAnswer != \"D\") & (math.isnan(row.MisconceptionDId) == False)):\n",
    "        misconception_text_row = miscon_data[(miscon_data.MisconceptionId==row.MisconceptionDId)]\n",
    "        misconception_id = row.MisconceptionDId\n",
    "        formatted_answer =  clean_math_text(row['AnswerDText'])\n",
    "        # flattened_data.append({'subjectName': row['SubjectName'], 'constructName': row['ConstructName'], 'latex_formatted_question': row['QuestionText'], 'question': clean_math_text(row['QuestionText']), 'latext_formatted_wrongAnswer': row['AnswerDText'], 'wrongAnswer': clean_math_text(row['AnswerDText']), 'misconception': misconception_row.MisconceptionName})\n",
    "\n",
    "    flattened_data.append({'text': f\"{clean_math_text(row['SubjectName'])} {clean_math_text(row['ConstructName'])} {clean_math_text(row['QuestionText'])} {formatted_answer}\", \"label\": int(misconception_id)})\n",
    "\n",
    "flattened_df = pd.DataFrame(flattened_data)\n",
    "# Sort by the 'label' column in ascending order \n",
    "flattened_df = flattened_df.sort_values(by='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5df628ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>angles in triangles find missing angles in a s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>measuring angles identify the number of degree...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>factorising into a single bracket factorise a ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>simplifying expressions by collecting like ter...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>simplifying expressions by collecting like ter...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "1421  angles in triangles find missing angles in a s...      0\n",
       "325   measuring angles identify the number of degree...      2\n",
       "1057  factorising into a single bracket factorise a ...      3\n",
       "998   simplifying expressions by collecting like ter...      4\n",
       "902   simplifying expressions by collecting like ter...      4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "507f11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save flattened data\n",
    "flattened_df.to_csv('./eedi-mining/model/flattened_misconceptions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1377b351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-11T21:33:29.755434Z",
     "iopub.status.busy": "2024-10-11T21:33:29.755000Z",
     "iopub.status.idle": "2024-10-11T21:33:29.761444Z",
     "shell.execute_reply": "2024-10-11T21:33:29.760316Z"
    },
    "papermill": {
     "duration": 0.018151,
     "end_time": "2024-10-11T21:33:29.763839",
     "exception": false,
     "start_time": "2024-10-11T21:33:29.745688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining a function to compute the cosine similarity between two embedding vectors\n",
    "def cosine_score(text):\n",
    "    # encoding the text\n",
    "    embeddings = model.encode(text)\n",
    "\n",
    "    # calculating the L2 norm of the embedding vector\n",
    "    norm1 = np.linalg.norm(embeddings[0])\n",
    "    norm2 = np.linalg.norm(embeddings[1])\n",
    "\n",
    "    # computing the cosine similarity\n",
    "    cosine_similarity_score = ((np.dot(embeddings[0],embeddings[1]))/(norm1*norm2))\n",
    "\n",
    "    return cosine_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5af7963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 2: 1, 3: 2, 4: 4, 9: 5, 11: 10, 14: 11, 20: 12, 21: 13, 22: 14, 27: 15, 28: 16, 29: 17, 31: 22, 32: 23, 33: 24, 35: 25, 36: 26, 38: 27, 39: 29, 42: 31, 48: 33, 49: 34, 51: 35, 55: 38, 57: 40, 58: 41, 60: 42, 61: 46, 66: 47, 68: 49, 70: 50, 71: 54, 74: 56, 76: 57, 77: 65, 78: 66, 81: 68, 82: 76, 83: 77, 84: 78, 86: 79, 91: 81, 95: 82, 101: 83, 102: 84, 103: 85, 105: 89, 106: 90, 107: 93, 108: 99, 109: 100, 110: 105, 113: 113, 114: 114, 118: 115, 119: 116, 120: 121, 126: 123, 127: 124, 130: 125, 131: 128, 132: 129, 133: 131, 134: 134, 138: 135, 141: 136, 142: 137, 143: 139, 146: 141, 154: 142, 159: 145, 161: 151, 162: 152, 164: 155, 166: 157, 167: 160, 172: 166, 176: 167, 186: 170, 187: 171, 189: 172, 191: 174, 197: 175, 207: 176, 211: 177, 212: 179, 217: 184, 219: 189, 220: 196, 221: 197, 226: 200, 227: 201, 228: 202, 230: 203, 233: 204, 234: 206, 236: 207, 244: 208, 245: 209, 247: 210, 248: 211, 249: 212, 251: 213, 252: 214, 253: 215, 255: 221, 256: 225, 261: 226, 264: 227, 265: 230, 268: 231, 270: 232, 271: 233, 278: 234, 280: 235, 282: 237, 283: 239, 287: 240, 289: 241, 290: 242, 292: 243, 293: 244, 295: 245, 297: 246, 300: 247, 303: 248, 305: 249, 306: 251, 307: 252, 308: 253, 309: 254, 317: 257, 322: 258, 329: 263, 331: 265, 332: 267, 337: 269, 339: 270, 340: 274, 344: 276, 346: 279, 347: 280, 349: 281, 353: 282, 357: 284, 362: 285, 363: 286, 364: 287, 366: 288, 370: 289, 373: 290, 374: 291, 376: 292, 377: 294, 378: 297, 379: 299, 380: 302, 381: 304, 382: 305, 384: 307, 389: 308, 391: 312, 393: 313, 396: 315, 397: 317, 398: 319, 400: 320, 405: 321, 414: 322, 418: 326, 421: 329, 422: 331, 423: 333, 424: 334, 427: 337, 433: 339, 436: 341, 438: 343, 439: 344, 441: 345, 443: 348, 445: 349, 446: 350, 447: 351, 449: 352, 450: 353, 451: 354, 452: 357, 458: 360, 461: 361, 464: 362, 466: 363, 467: 364, 470: 366, 471: 367, 474: 368, 481: 369, 483: 372, 488: 375, 491: 377, 492: 378, 495: 379, 498: 380, 499: 381, 508: 382, 510: 383, 512: 388, 521: 389, 524: 390, 527: 391, 528: 394, 531: 395, 533: 396, 537: 397, 539: 400, 542: 401, 547: 407, 549: 408, 550: 413, 551: 414, 554: 415, 556: 419, 557: 426, 563: 429, 565: 431, 567: 432, 568: 433, 570: 435, 572: 436, 573: 437, 577: 438, 578: 439, 581: 440, 583: 446, 585: 449, 588: 450, 591: 451, 594: 452, 599: 454, 601: 455, 602: 456, 604: 457, 606: 459, 608: 460, 609: 461, 611: 462, 614: 463, 616: 464, 618: 468, 620: 469, 624: 470, 625: 471, 626: 472, 629: 473, 630: 474, 631: 477, 637: 478, 638: 480, 639: 481, 642: 483, 643: 484, 644: 485, 648: 487, 649: 488, 650: 489, 653: 490, 655: 491, 657: 493, 658: 495, 659: 496, 661: 498, 664: 499, 670: 501, 671: 503, 672: 505, 673: 507, 674: 510, 680: 511, 684: 513, 685: 514, 686: 516, 687: 519, 690: 525, 691: 528, 695: 529, 699: 533, 702: 535, 704: 536, 706: 538, 710: 541, 711: 542, 712: 543, 713: 544, 715: 545, 719: 546, 725: 549, 727: 550, 729: 551, 732: 552, 734: 554, 736: 555, 739: 557, 742: 558, 743: 560, 746: 562, 747: 563, 751: 564, 754: 565, 756: 566, 758: 567, 759: 569, 760: 571, 762: 572, 766: 574, 767: 576, 772: 578, 773: 579, 779: 581, 780: 582, 784: 585, 789: 586, 790: 588, 791: 591, 792: 593, 793: 594, 794: 595, 795: 596, 796: 597, 797: 600, 800: 602, 806: 604, 807: 607, 808: 608, 811: 610, 812: 611, 816: 612, 820: 613, 823: 614, 828: 618, 829: 619, 832: 620, 834: 621, 836: 622, 838: 627, 840: 628, 843: 629, 848: 630, 860: 634, 868: 635, 870: 636, 871: 637, 872: 638, 880: 639, 882: 640, 888: 642, 890: 643, 894: 644, 895: 645, 900: 646, 902: 647, 904: 648, 905: 650, 906: 651, 907: 657, 910: 658, 911: 660, 925: 661, 926: 663, 930: 665, 931: 667, 935: 668, 936: 671, 940: 672, 947: 674, 950: 675, 952: 676, 955: 677, 959: 678, 960: 679, 961: 680, 964: 681, 965: 682, 968: 684, 969: 685, 971: 687, 972: 688, 974: 698, 975: 699, 978: 700, 980: 701, 981: 702, 982: 705, 986: 706, 987: 707, 989: 708, 990: 711, 991: 712, 1007: 715, 1009: 716, 1012: 719, 1013: 721, 1016: 722, 1017: 723, 1025: 724, 1026: 727, 1028: 729, 1029: 730, 1031: 731, 1032: 732, 1035: 733, 1036: 734, 1040: 735, 1043: 736, 1044: 739, 1046: 740, 1047: 742, 1048: 743, 1049: 744, 1051: 745, 1055: 750, 1057: 751, 1063: 752, 1066: 754, 1070: 756, 1072: 764, 1073: 766, 1074: 770, 1075: 771, 1078: 772, 1079: 773, 1082: 774, 1083: 775, 1089: 776, 1098: 777, 1099: 778, 1100: 780, 1103: 783, 1107: 784, 1108: 786, 1110: 787, 1115: 788, 1118: 789, 1119: 790, 1120: 792, 1123: 793, 1124: 794, 1126: 795, 1128: 797, 1130: 802, 1133: 803, 1134: 804, 1138: 808, 1140: 809, 1144: 810, 1145: 811, 1148: 815, 1150: 816, 1155: 818, 1156: 820, 1157: 821, 1158: 822, 1163: 823, 1164: 825, 1166: 826, 1168: 827, 1175: 828, 1176: 830, 1180: 835, 1181: 836, 1184: 839, 1186: 841, 1187: 842, 1188: 844, 1190: 845, 1192: 846, 1193: 847, 1198: 851, 1204: 852, 1206: 854, 1207: 856, 1208: 857, 1212: 858, 1214: 885, 1216: 886, 1224: 887, 1225: 888, 1226: 890, 1229: 891, 1230: 892, 1233: 893, 1235: 894, 1237: 895, 1240: 897, 1244: 898, 1248: 907, 1250: 909, 1252: 910, 1255: 911, 1258: 912, 1259: 913, 1260: 914, 1261: 915, 1263: 916, 1264: 917, 1265: 919, 1277: 920, 1278: 921, 1280: 923, 1282: 924, 1288: 925, 1290: 927, 1292: 929, 1293: 930, 1294: 933, 1295: 934, 1302: 935, 1303: 936, 1304: 937, 1306: 938, 1307: 939, 1310: 944, 1311: 945, 1312: 946, 1316: 947, 1318: 950, 1319: 951, 1320: 952, 1322: 955, 1324: 956, 1326: 957, 1327: 958, 1329: 959, 1333: 960, 1334: 961, 1336: 964, 1338: 967, 1340: 968, 1344: 969, 1348: 971, 1349: 972, 1350: 973, 1354: 974, 1356: 975, 1360: 977, 1361: 978, 1364: 979, 1365: 984, 1370: 986, 1373: 987, 1374: 989, 1379: 1006, 1380: 1007, 1383: 1017, 1386: 1018, 1388: 1019, 1389: 1020, 1400: 1023, 1402: 1025, 1408: 1026, 1410: 1027, 1411: 1028, 1416: 1032, 1417: 1035, 1419: 1037, 1420: 1038, 1424: 1039, 1425: 1040, 1426: 1041, 1427: 1042, 1429: 1044, 1430: 1045, 1431: 1046, 1432: 1047, 1433: 1048, 1435: 1050, 1440: 1051, 1443: 1052, 1444: 1053, 1445: 1055, 1447: 1056, 1449: 1057, 1450: 1062, 1452: 1063, 1457: 1064, 1459: 1065, 1460: 1066, 1467: 1067, 1469: 1068, 1471: 1069, 1473: 1071, 1480: 1073, 1488: 1075, 1491: 1076, 1494: 1079, 1499: 1080, 1507: 1094, 1508: 1095, 1509: 1096, 1510: 1103, 1511: 1104, 1513: 1106, 1514: 1112, 1519: 1114, 1520: 1117, 1523: 1118, 1527: 1124, 1528: 1126, 1529: 1129, 1530: 1131, 1532: 1133, 1534: 1134, 1535: 1137, 1536: 1138, 1537: 1139, 1540: 1142, 1542: 1145, 1543: 1147, 1550: 1148, 1554: 1151, 1556: 1152, 1558: 1155, 1559: 1156, 1561: 1157, 1566: 1158, 1568: 1159, 1577: 1160, 1582: 1164, 1585: 1165, 1588: 1166, 1591: 1167, 1593: 1168, 1595: 1169, 1597: 1181, 1598: 1182, 1599: 1183, 1601: 1186, 1605: 1187, 1606: 1189, 1608: 1190, 1611: 1191, 1613: 1192, 1616: 1193, 1619: 1194, 1621: 1197, 1622: 1199, 1623: 1200, 1626: 1202, 1628: 1203, 1630: 1204, 1631: 1211, 1632: 1212, 1636: 1213, 1639: 1215, 1640: 1216, 1644: 1219, 1646: 1222, 1648: 1224, 1651: 1225, 1652: 1227, 1655: 1229, 1656: 1230, 1658: 1231, 1659: 1233, 1660: 1236, 1661: 1237, 1663: 1238, 1664: 1240, 1666: 1241, 1667: 1242, 1668: 1243, 1670: 1245, 1671: 1246, 1672: 1247, 1675: 1248, 1676: 1249, 1678: 1252, 1680: 1255, 1682: 1257, 1686: 1260, 1687: 1261, 1690: 1263, 1693: 1264, 1694: 1265, 1696: 1266, 1697: 1268, 1701: 1269, 1704: 1271, 1705: 1273, 1706: 1276, 1707: 1277, 1708: 1279, 1710: 1280, 1714: 1281, 1715: 1282, 1717: 1283, 1721: 1284, 1725: 1285, 1730: 1288, 1731: 1289, 1734: 1290, 1735: 1291, 1737: 1294, 1741: 1295, 1743: 1298, 1744: 1299, 1746: 1300, 1749: 1301, 1751: 1302, 1756: 1303, 1757: 1304, 1759: 1305, 1761: 1306, 1764: 1308, 1766: 1310, 1769: 1312, 1773: 1317, 1775: 1318, 1782: 1319, 1783: 1321, 1784: 1322, 1786: 1324, 1787: 1325, 1788: 1326, 1790: 1327, 1791: 1331, 1792: 1334, 1793: 1335, 1803: 1337, 1805: 1339, 1809: 1340, 1814: 1341, 1818: 1342, 1820: 1344, 1824: 1348, 1825: 1349, 1828: 1354, 1832: 1355, 1834: 1356, 1836: 1357, 1837: 1358, 1839: 1360, 1849: 1361, 1851: 1362, 1860: 1363, 1862: 1364, 1863: 1366, 1870: 1367, 1871: 1368, 1872: 1371, 1875: 1372, 1880: 1389, 1881: 1390, 1882: 1391, 1883: 1393, 1884: 1394, 1887: 1396, 1897: 1397, 1898: 1398, 1900: 1401, 1906: 1403, 1907: 1404, 1908: 1405, 1911: 1406, 1914: 1407, 1915: 1408, 1917: 1409, 1918: 1411, 1920: 1413, 1921: 1414, 1925: 1415, 1927: 1418, 1929: 1419, 1937: 1420, 1939: 1421, 1942: 1422, 1944: 1423, 1945: 1424, 1950: 1425, 1954: 1426, 1957: 1427, 1960: 1428, 1965: 1430, 1966: 1432, 1970: 1433, 1971: 1434, 1973: 1435, 1976: 1437, 1978: 1439, 1981: 1441, 1982: 1442, 1984: 1444, 1986: 1445, 1988: 1451, 1990: 1461, 1994: 1462, 1995: 1463, 1996: 1464, 1999: 1465, 2003: 1466, 2016: 1467, 2017: 1468, 2020: 1469, 2021: 1470, 2023: 1471, 2024: 1472, 2026: 1474, 2027: 1475, 2030: 1478, 2031: 1479, 2032: 1480, 2034: 1481, 2037: 1482, 2039: 1483, 2042: 1484, 2043: 1487, 2046: 1489, 2047: 1490, 2048: 1491, 2050: 1492, 2053: 1496, 2054: 1497, 2055: 1499, 2056: 1500, 2066: 1501, 2068: 1502, 2069: 1503, 2071: 1505, 2073: 1507, 2077: 1508, 2078: 1510, 2084: 1511, 2085: 1513, 2087: 1515, 2091: 1516, 2094: 1517, 2095: 1524, 2098: 1525, 2105: 1526, 2109: 1529, 2111: 1530, 2113: 1536, 2114: 1537, 2119: 1538, 2123: 1539, 2124: 1540, 2127: 1542, 2131: 1543, 2132: 1546, 2133: 1547, 2137: 1549, 2138: 1551, 2139: 1552, 2142: 1554, 2143: 1560, 2154: 1562, 2155: 1563, 2159: 1564, 2160: 1565, 2161: 1566, 2162: 1567, 2166: 1568, 2173: 1569, 2175: 1570, 2178: 1571, 2185: 1576, 2187: 1577, 2190: 1578, 2198: 1580, 2199: 1581, 2203: 1582, 2204: 1583, 2208: 1584, 2209: 1585, 2214: 1586, 2215: 1587, 2225: 1588, 2226: 1589, 2228: 1592, 2230: 1594, 2231: 1595, 2234: 1599, 2238: 1600, 2240: 1603, 2245: 1604, 2248: 1605, 2250: 1606, 2251: 1607, 2252: 1611, 2256: 1613, 2260: 1614, 2261: 1615, 2262: 1618, 2264: 1621, 2265: 1622, 2266: 1623, 2269: 1624, 2271: 1629, 2273: 1630, 2275: 1631, 2279: 1632, 2282: 1633, 2284: 1634, 2285: 1635, 2286: 1636, 2291: 1637, 2296: 1638, 2301: 1639, 2302: 1640, 2305: 1642, 2306: 1647, 2307: 1648, 2308: 1653, 2309: 1654, 2312: 1655, 2314: 1656, 2316: 1668, 2318: 1670, 2326: 1672, 2327: 1673, 2329: 1674, 2330: 1680, 2331: 1682, 2332: 1683, 2333: 1684, 2334: 1685, 2340: 1686, 2343: 1687, 2345: 1688, 2346: 1693, 2350: 1694, 2351: 1695, 2352: 1700, 2353: 1702, 2354: 1704, 2355: 1709, 2356: 1710, 2359: 1720, 2361: 1722, 2362: 1726, 2363: 1727, 2364: 1728, 2365: 1730, 2368: 1731, 2373: 1732, 2374: 1733, 2375: 1734, 2376: 1738, 2377: 1740, 2386: 1742, 2389: 1744, 2392: 1753, 2395: 1754, 2397: 1755, 2398: 1757, 2408: 1758, 2412: 1760, 2413: 1761, 2414: 1762, 2417: 1764, 2423: 1765, 2425: 1766, 2426: 1767, 2427: 1771, 2428: 1772, 2432: 1773, 2433: 1774, 2435: 1775, 2436: 1778, 2437: 1779, 2438: 1782, 2443: 1783, 2453: 1784, 2454: 1787, 2458: 1789, 2461: 1791, 2464: 1792, 2466: 1793, 2469: 1794, 2472: 1797, 2475: 1798, 2476: 1799, 2479: 1801, 2480: 1803, 2481: 1811, 2485: 1812, 2488: 1813, 2489: 1815, 2491: 1816, 2492: 1817, 2493: 1819, 2494: 1820, 2501: 1821, 2504: 1822, 2505: 1823, 2511: 1824, 2512: 1825, 2514: 1828, 2515: 1829, 2516: 1830, 2517: 1831, 2519: 1832, 2520: 1833, 2524: 1834, 2525: 1835, 2530: 1836, 2531: 1837, 2532: 1843, 2535: 1844, 2537: 1845, 2542: 1846, 2543: 1847, 2546: 1848, 2549: 1849, 2555: 1851, 2558: 1852, 2561: 1854, 2563: 1855, 2565: 1856, 2566: 1858, 2576: 1860, 2577: 1861, 2579: 1863, 2583: 1865, 2585: 1867, 2586: 1868}\n",
      "tensor([   0,    1,    2,  ..., 1867, 1867, 1868])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# Sample text data and labels\n",
    "# Prepare your dataset (replace with your own data)\n",
    "texts = flattened_df['text'].to_list()\n",
    "original_labels =flattened_df['label'].to_list()\n",
    "\n",
    "# Create a mapping dictionary\n",
    "label_mapping = {label: idx for idx, label in enumerate(original_labels)}\n",
    "\n",
    "print(label_mapping)\n",
    "\n",
    "# Original labels for the data\n",
    "labels = torch.tensor(original_labels, dtype=torch.long)\n",
    "\n",
    "# Map original labels to sequential labels\n",
    "mapped_labels = torch.tensor([label_mapping[label.item()] for label in labels], dtype=torch.long)\n",
    "print (mapped_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3209ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   0,    1,    2,  ..., 1867, 1867, 1868])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "\n",
    "# Load the tokenizer and model\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"AnReu/math_pretrained_bert\")\n",
    "model = AutoModelForPreTraining.from_pretrained(\"AnReu/math_pretrained_bert\")\n",
    "\n",
    "\n",
    "class MathMisconceptionsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        print(labels)\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Flatten the encoding tensors\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
    "        logging.info(label)\n",
    "        return item\n",
    "\n",
    "\n",
    "# get data\n",
    "model_dir = 'c:/ai_ml/kaggle/eedi-mining/model'\n",
    "#           'C:\\ai_ml\\kaggle\\eedi-mining\\model\\flattened_misconceptions.csv'\n",
    "model_data=f\"{model_dir}/flattened_misconceptions.csv\"\n",
    "\n",
    "out_dir = model_dir\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "max_length = 256  # Maximum length for tokenization\n",
    "#train_dataset = MathMisconceptionsDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "#val_dataset = MathMisconceptionsDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "\n",
    "# Create the dataset\n",
    "dataset = MathMisconceptionsDataset(texts, mapped_labels, tokenizer, max_length)\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Save the datasets\n",
    "model_train_dataset_name=f\"{model_dir}/math_misconceptions_train_dataset.pt\"\n",
    "torch.save(train_dataset, model_train_dataset_name)\n",
    "\n",
    "model_val_dataset_name=f\"{model_dir}/math_misconceptions_val_dataset.pt\"\n",
    "torch.save(val_dataset, model_val_dataset_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3370fb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billl\\AppData\\Local\\Temp\\ipykernel_6740\\82937343.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(label, dtype=torch.long)\n",
      "2024-11-17 20:16:41 - INFO - tensor(450)\n",
      "2024-11-17 20:16:41 - INFO - tensor(177)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1670)\n",
      "2024-11-17 20:16:41 - INFO - tensor(400)\n",
      "2024-11-17 20:16:41 - INFO - tensor(698)\n",
      "2024-11-17 20:16:41 - INFO - tensor(79)\n",
      "2024-11-17 20:16:41 - INFO - tensor(657)\n",
      "2024-11-17 20:16:41 - INFO - tensor(971)\n",
      "2024-11-17 20:16:41 - INFO - tensor(408)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1288)\n",
      "2024-11-17 20:16:41 - INFO - tensor(496)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1560)\n",
      "2024-11-17 20:16:41 - INFO - tensor(797)\n",
      "2024-11-17 20:16:41 - INFO - tensor(885)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1341)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1168)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1017)\n",
      "2024-11-17 20:16:41 - INFO - tensor(956)\n",
      "2024-11-17 20:16:41 - INFO - tensor(315)\n",
      "2024-11-17 20:16:41 - INFO - tensor(591)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1324)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1530)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1020)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1339)\n",
      "2024-11-17 20:16:41 - INFO - tensor(885)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1294)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1137)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1653)\n",
      "2024-11-17 20:16:41 - INFO - tensor(483)\n",
      "2024-11-17 20:16:41 - INFO - tensor(76)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Number of samples : 1495 | Number of batches: 50\n",
      " - Number of samples : 374 | Number of batches: 13\n",
      "{'input_ids': tensor([[    2,  2310,    17,  ...,     0,     0,     0],\n",
      "        [    2,   683,   201,  ...,     0,     0,     0],\n",
      "        [    2,    85,   231,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2, 19583,   128,  ...,     0,     0,     0],\n",
      "        [    2,  9138,  6907,  ...,     0,     0,     0],\n",
      "        [    2, 22716,    13,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 450,  177, 1670,  400,  698,   79,  657,  971,  408, 1288,  496, 1560,\n",
      "         797,  885, 1341, 1168, 1017,  956,  315,  591, 1324, 1530, 1020, 1339,\n",
      "         885, 1294, 1137, 1653,  483,   76])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:16:41 - INFO - tensor(105)\n",
      "2024-11-17 20:16:41 - INFO - tensor(820)\n",
      "2024-11-17 20:16:41 - INFO - tensor(788)\n",
      "2024-11-17 20:16:41 - INFO - tensor(89)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1276)\n",
      "2024-11-17 20:16:41 - INFO - tensor(588)\n",
      "2024-11-17 20:16:41 - INFO - tensor(674)\n",
      "2024-11-17 20:16:41 - INFO - tensor(459)\n",
      "2024-11-17 20:16:41 - INFO - tensor(50)\n",
      "2024-11-17 20:16:41 - INFO - tensor(786)\n",
      "2024-11-17 20:16:41 - INFO - tensor(783)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1006)\n",
      "2024-11-17 20:16:41 - INFO - tensor(400)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1079)\n",
      "2024-11-17 20:16:41 - INFO - tensor(501)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1843)\n",
      "2024-11-17 20:16:41 - INFO - tensor(1414)\n",
      "2024-11-17 20:16:41 - INFO - tensor(510)\n",
      "2024-11-17 20:16:41 - INFO - tensor(377)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1629)\n",
      "2024-11-17 20:16:42 - INFO - tensor(76)\n",
      "2024-11-17 20:16:42 - INFO - tensor(413)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1055)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1367)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1191)\n",
      "2024-11-17 20:16:42 - INFO - tensor(627)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1794)\n",
      "2024-11-17 20:16:42 - INFO - tensor(810)\n",
      "2024-11-17 20:16:42 - INFO - tensor(426)\n",
      "2024-11-17 20:16:42 - INFO - tensor(137)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1565)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1407)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1073)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1263)\n",
      "2024-11-17 20:16:42 - INFO - tensor(348)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1229)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1680)\n",
      "2024-11-17 20:16:42 - INFO - tensor(201)\n",
      "2024-11-17 20:16:42 - INFO - tensor(907)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1551)\n",
      "2024-11-17 20:16:42 - INFO - tensor(944)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1581)\n",
      "2024-11-17 20:16:42 - INFO - tensor(802)\n",
      "2024-11-17 20:16:42 - INFO - tensor(727)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1389)\n",
      "2024-11-17 20:16:42 - INFO - tensor(885)\n",
      "2024-11-17 20:16:42 - INFO - tensor(533)\n",
      "2024-11-17 20:16:42 - INFO - tensor(716)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1047)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1215)\n",
      "2024-11-17 20:16:42 - INFO - tensor(35)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1310)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1656)\n",
      "2024-11-17 20:16:42 - INFO - tensor(793)\n",
      "2024-11-17 20:16:42 - INFO - tensor(151)\n",
      "2024-11-17 20:16:42 - INFO - tensor(360)\n",
      "2024-11-17 20:16:42 - INFO - tensor(478)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1720)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1837)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1562)\n",
      "2024-11-17 20:16:42 - INFO - tensor(752)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1445)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2, 15154, 11689,  ...,     0,     0,     0],\n",
      "        [    2, 18542, 10885,  ...,     0,     0,     0],\n",
      "        [    2, 11173,  9539,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2, 10095,    17,  ...,     0,     0,     0],\n",
      "        [    2, 19910,    77,  ...,     0,     0,     0],\n",
      "        [    2,  6745, 11173,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 105,  820,  788,   89, 1276,  588,  674,  459,   50,  786,  783, 1006,\n",
      "         400, 1079,  501, 1843, 1414,  510,  377, 1629,   76,  413, 1055, 1367,\n",
      "        1191,  627, 1794,  810,  426,  137])}\n",
      "{'input_ids': tensor([[    2,  5780,    18,  ...,     0,     0,     0],\n",
      "        [    2, 10177,    16,  ...,     0,     0,     0],\n",
      "        [    2,  3821,  1560,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2, 26314,    68,  ...,     0,     0,     0],\n",
      "        [    2,  1476,   217,  ...,     0,     0,     0],\n",
      "        [    2, 10885,    18,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1565, 1407, 1073, 1263,  348, 1229, 1680,  201,  907, 1551,  944, 1581,\n",
      "         802,  727, 1389,  885,  533,  716, 1047, 1215,   35, 1310, 1656,  793,\n",
      "         151,  360,  478, 1720, 1837, 1562])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:16:42 - INFO - tensor(344)\n",
      "2024-11-17 20:16:42 - INFO - tensor(284)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1094)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1418)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1203)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1372)\n",
      "2024-11-17 20:16:42 - INFO - tensor(82)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1276)\n",
      "2024-11-17 20:16:42 - INFO - tensor(730)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1753)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1507)\n",
      "2024-11-17 20:16:42 - INFO - tensor(533)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1079)\n",
      "2024-11-17 20:16:42 - INFO - tensor(608)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1397)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1283)\n",
      "2024-11-17 20:16:42 - INFO - tensor(924)\n",
      "2024-11-17 20:16:42 - INFO - tensor(155)\n",
      "2024-11-17 20:16:42 - INFO - tensor(545)\n",
      "2024-11-17 20:16:42 - INFO - tensor(196)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1576)\n",
      "2024-11-17 20:16:42 - INFO - tensor(139)\n",
      "2024-11-17 20:16:42 - INFO - tensor(257)\n",
      "2024-11-17 20:16:42 - INFO - tensor(750)\n",
      "2024-11-17 20:16:42 - INFO - tensor(269)\n",
      "2024-11-17 20:16:42 - INFO - tensor(581)\n",
      "2024-11-17 20:16:42 - INFO - tensor(348)\n",
      "2024-11-17 20:16:42 - INFO - tensor(326)\n",
      "2024-11-17 20:16:42 - INFO - tensor(116)\n",
      "2024-11-17 20:16:42 - INFO - tensor(312)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1478)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1510)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1560)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1252)\n",
      "2024-11-17 20:16:42 - INFO - tensor(394)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1348)\n",
      "2024-11-17 20:16:42 - INFO - tensor(329)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1245)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1484)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1670)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1668)\n",
      "2024-11-17 20:16:42 - INFO - tensor(733)\n",
      "2024-11-17 20:16:42 - INFO - tensor(950)\n",
      "2024-11-17 20:16:42 - INFO - tensor(307)\n",
      "2024-11-17 20:16:42 - INFO - tensor(525)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1502)\n",
      "2024-11-17 20:16:42 - INFO - tensor(329)\n",
      "2024-11-17 20:16:42 - INFO - tensor(525)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1103)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1354)\n",
      "2024-11-17 20:16:42 - INFO - tensor(802)\n",
      "2024-11-17 20:16:42 - INFO - tensor(957)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1529)\n",
      "2024-11-17 20:16:42 - INFO - tensor(167)\n",
      "2024-11-17 20:16:42 - INFO - tensor(350)\n",
      "2024-11-17 20:16:42 - INFO - tensor(436)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1064)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1843)\n",
      "2024-11-17 20:16:42 - INFO - tensor(426)\n",
      "2024-11-17 20:16:42 - INFO - tensor(22)\n",
      "2024-11-17 20:16:42 - INFO - tensor(671)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1356)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1720)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  3584, 25432,  ...,     0,     0,     0],\n",
      "        [    2,  1174,  4825,  ...,     0,     0,     0],\n",
      "        [    2, 17442,   128,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  3584, 25432,  ...,     0,     0,     0],\n",
      "        [    2,    85,  8406,  ...,     0,     0,     0],\n",
      "        [    2,  3932,  7552,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 752, 1445,  344,  284, 1094, 1418, 1203, 1372,   82, 1276,  730, 1753,\n",
      "        1507,  533, 1079,  608, 1397, 1283,  924,  155,  545,  196, 1576,  139,\n",
      "         257,  750,  269,  581,  348,  326])}\n",
      "{'input_ids': tensor([[    2,   683,   201,  ...,     0,     0,     0],\n",
      "        [    2, 22716,  1560,  ...,     0,     0,     0],\n",
      "        [    2, 15775, 10885,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  1174, 13832,  ...,     0,     0,     0],\n",
      "        [    2,   862,    18,  ...,     0,     0,     0],\n",
      "        [    2,  4458,  5250,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 116,  312, 1478, 1510, 1560, 1252,  394, 1348,  329, 1245, 1484, 1670,\n",
      "        1668,  733,  950,  307,  525, 1502,  329,  525, 1103, 1354,  802,  957,\n",
      "        1529,  167,  350,  436, 1064, 1843])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:16:42 - INFO - tensor(231)\n",
      "2024-11-17 20:16:42 - INFO - tensor(477)\n",
      "2024-11-17 20:16:42 - INFO - tensor(46)\n",
      "2024-11-17 20:16:42 - INFO - tensor(215)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1576)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1693)\n",
      "2024-11-17 20:16:42 - INFO - tensor(351)\n",
      "2024-11-17 20:16:42 - INFO - tensor(951)\n",
      "2024-11-17 20:16:42 - INFO - tensor(569)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1470)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1126)\n",
      "2024-11-17 20:16:42 - INFO - tensor(160)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1680)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1791)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1389)\n",
      "2024-11-17 20:16:42 - INFO - tensor(299)\n",
      "2024-11-17 20:16:42 - INFO - tensor(557)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1355)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1042)\n",
      "2024-11-17 20:16:42 - INFO - tensor(65)\n",
      "2024-11-17 20:16:42 - INFO - tensor(397)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1037)\n",
      "2024-11-17 20:16:42 - INFO - tensor(212)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1605)\n",
      "2024-11-17 20:16:42 - INFO - tensor(432)\n",
      "2024-11-17 20:16:42 - INFO - tensor(394)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1592)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1277)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1324)\n",
      "2024-11-17 20:16:42 - INFO - tensor(839)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1536)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1856)\n",
      "2024-11-17 20:16:42 - INFO - tensor(967)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1068)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1542)\n",
      "2024-11-17 20:16:42 - INFO - tensor(778)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1268)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1539)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1224)\n",
      "2024-11-17 20:16:42 - INFO - tensor(388)\n",
      "2024-11-17 20:16:42 - INFO - tensor(665)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1560)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1062)\n",
      "2024-11-17 20:16:42 - INFO - tensor(637)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1442)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1668)\n",
      "2024-11-17 20:16:42 - INFO - tensor(413)\n",
      "2024-11-17 20:16:42 - INFO - tensor(121)\n",
      "2024-11-17 20:16:42 - INFO - tensor(312)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1066)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1017)\n",
      "2024-11-17 20:16:42 - INFO - tensor(572)\n",
      "2024-11-17 20:16:42 - INFO - tensor(721)\n",
      "2024-11-17 20:16:42 - INFO - tensor(299)\n",
      "2024-11-17 20:16:42 - INFO - tensor(113)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1854)\n",
      "2024-11-17 20:16:42 - INFO - tensor(579)\n",
      "2024-11-17 20:16:42 - INFO - tensor(802)\n",
      "2024-11-17 20:16:42 - INFO - tensor(676)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1288)\n",
      "2024-11-17 20:16:42 - INFO - tensor(78)\n",
      "2024-11-17 20:16:42 - INFO - tensor(343)\n",
      "2024-11-17 20:16:42 - INFO - tensor(49)\n",
      "2024-11-17 20:16:42 - INFO - tensor(586)\n",
      "2024-11-17 20:16:42 - INFO - tensor(329)\n",
      "2024-11-17 20:16:42 - INFO - tensor(634)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1224)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1266)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1327)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  6745, 11173,  ...,     0,     0,     0],\n",
      "        [    2,  1174, 13832,  ...,     0,     0,     0],\n",
      "        [    2,  6745, 11173,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2, 10885,    18,  ...,     0,     0,     0],\n",
      "        [    2,   735,    18,  ...,     0,     0,     0],\n",
      "        [    2,  2310,    17,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 426,   22,  671, 1356, 1720,  231,  477,   46,  215, 1576, 1693,  351,\n",
      "         951,  569, 1470, 1126,  160, 1680, 1791, 1389,  299,  557, 1355, 1042,\n",
      "          65,  397, 1037,  212, 1605,  432])}\n",
      "{'input_ids': tensor([[    2, 13280,    19,  ...,     0,     0,     0],\n",
      "        [    2,    89, 11173,  ...,     0,     0,     0],\n",
      "        [    2,  2125,  5334,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,    85, 18469,  ...,     0,     0,     0],\n",
      "        [    2,    13, 26849,  ...,     0,     0,     0],\n",
      "        [    2,  2841,    16,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 394, 1592, 1277, 1324,  839, 1536, 1856,  967, 1068, 1542,  778, 1268,\n",
      "        1539, 1224,  388,  665, 1560, 1062,  637, 1442, 1668,  413,  121,  312,\n",
      "        1066, 1017,  572,  721,  299,  113])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:16:42 - INFO - tensor(38)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1560)\n",
      "2024-11-17 20:16:42 - INFO - tensor(555)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1104)\n",
      "2024-11-17 20:16:42 - INFO - tensor(955)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1463)\n",
      "2024-11-17 20:16:42 - INFO - tensor(166)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1236)\n",
      "2024-11-17 20:16:42 - INFO - tensor(964)\n",
      "2024-11-17 20:16:42 - INFO - tensor(1334)\n",
      "2024-11-17 20:16:42 - INFO - tensor(221)\n",
      "2024-11-17 20:16:43 - INFO - tensor(225)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1848)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1358)\n",
      "2024-11-17 20:16:43 - INFO - tensor(407)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1112)\n",
      "2024-11-17 20:16:43 - INFO - tensor(152)\n",
      "2024-11-17 20:16:43 - INFO - tensor(885)\n",
      "2024-11-17 20:16:43 - INFO - tensor(907)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1753)\n",
      "2024-11-17 20:16:43 - INFO - tensor(468)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1025)\n",
      "2024-11-17 20:16:43 - INFO - tensor(440)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1789)\n",
      "2024-11-17 20:16:43 - INFO - tensor(675)\n",
      "2024-11-17 20:16:43 - INFO - tensor(764)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1578)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1437)\n",
      "2024-11-17 20:16:43 - INFO - tensor(835)\n",
      "2024-11-17 20:16:43 - INFO - tensor(341)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1131)\n",
      "2024-11-17 20:16:43 - INFO - tensor(206)\n",
      "2024-11-17 20:16:43 - INFO - tensor(744)\n",
      "2024-11-17 20:16:43 - INFO - tensor(914)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1310)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1298)\n",
      "2024-11-17 20:16:43 - INFO - tensor(913)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1680)\n",
      "2024-11-17 20:16:43 - INFO - tensor(984)\n",
      "2024-11-17 20:16:43 - INFO - tensor(128)\n",
      "2024-11-17 20:16:43 - INFO - tensor(907)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1238)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1007)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1638)\n",
      "2024-11-17 20:16:43 - INFO - tensor(184)\n",
      "2024-11-17 20:16:43 - INFO - tensor(698)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2, 10177,    16,  ...,     0,     0,     0],\n",
      "        [    2, 13280,    19,  ...,     0,     0,     0],\n",
      "        [    2,  6745, 12853,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  4275,    18,  ...,     0,     0,     0],\n",
      "        [    2,  2841,    16,  ...,     0,     0,     0],\n",
      "        [    2,  4721,    17,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1854,  579,  802,  676, 1288,   78,  343,   49,  586,  329,  634, 1224,\n",
      "        1266, 1327,   38, 1560,  555, 1104,  955, 1463,  166, 1236,  964, 1334,\n",
      "         221,  225, 1848, 1358,  407, 1112])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:16:43 - INFO - tensor(597)\n",
      "2024-11-17 20:16:43 - INFO - tensor(207)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1779)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1389)\n",
      "2024-11-17 20:16:43 - INFO - tensor(77)\n",
      "2024-11-17 20:16:43 - INFO - tensor(487)\n",
      "2024-11-17 20:16:43 - INFO - tensor(362)\n",
      "2024-11-17 20:16:43 - INFO - tensor(715)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1236)\n",
      "2024-11-17 20:16:43 - INFO - tensor(808)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1211)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1501)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1594)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1366)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1589)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1389)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1155)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1134)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1461)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1478)\n",
      "2024-11-17 20:16:43 - INFO - tensor(267)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  6745, 11173,  ...,     0,     0,     0],\n",
      "        [    2,  6745, 12853,  ...,     0,     0,     0],\n",
      "        [    2,   560,    68,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,    89, 11173,  ...,     0,     0,     0],\n",
      "        [    2,  4721,    17,  ...,     0,     0,     0],\n",
      "        [    2, 26314,    68,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 152,  885,  907, 1753,  468, 1025,  440, 1789,  675,  764, 1578, 1437,\n",
      "         835,  341, 1131,  206,  744,  914, 1310, 1298,  913, 1680,  984,  128,\n",
      "         907, 1238, 1007, 1638,  184,  698])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:16:43 - INFO - tensor(581)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1181)\n",
      "2024-11-17 20:16:43 - INFO - tensor(379)\n",
      "2024-11-17 20:16:43 - INFO - tensor(841)\n",
      "2024-11-17 20:16:43 - INFO - tensor(777)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1428)\n",
      "2024-11-17 20:16:43 - INFO - tensor(815)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1349)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1080)\n",
      "2024-11-17 20:16:43 - INFO - tensor(113)\n",
      "2024-11-17 20:16:43 - INFO - tensor(128)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1845)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1236)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1326)\n",
      "2024-11-17 20:16:43 - INFO - tensor(818)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1849)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1124)\n",
      "2024-11-17 20:16:43 - INFO - tensor(909)\n",
      "2024-11-17 20:16:43 - INFO - tensor(786)\n",
      "2024-11-17 20:16:43 - INFO - tensor(916)\n",
      "2024-11-17 20:16:43 - INFO - tensor(170)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1569)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1642)\n",
      "2024-11-17 20:16:43 - INFO - tensor(783)\n",
      "2024-11-17 20:16:43 - INFO - tensor(366)\n",
      "2024-11-17 20:16:43 - INFO - tensor(594)\n",
      "2024-11-17 20:16:43 - INFO - tensor(535)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1142)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1742)\n",
      "2024-11-17 20:16:43 - INFO - tensor(774)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1801)\n",
      "2024-11-17 20:16:43 - INFO - tensor(846)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1813)\n",
      "2024-11-17 20:16:43 - INFO - tensor(672)\n",
      "2024-11-17 20:16:43 - INFO - tensor(809)\n",
      "2024-11-17 20:16:43 - INFO - tensor(933)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1738)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1192)\n",
      "2024-11-17 20:16:43 - INFO - tensor(446)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1551)\n",
      "2024-11-17 20:16:43 - INFO - tensor(986)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  6960,  8676,  ...,     0,     0,     0],\n",
      "        [    2,  5334, 10459,  ...,     0,     0,     0],\n",
      "        [    2,   683,   201,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  6089,   217,  ...,     0,     0,     0],\n",
      "        [    2, 28257,    68,  ...,     0,     0,     0],\n",
      "        [    2,  3007,    14,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 597,  207, 1779, 1389,   77,  487,  362,  715, 1236,  808, 1211, 1501,\n",
      "        1594, 1366, 1589, 1389, 1155, 1134, 1461, 1478,  267,  581, 1181,  379,\n",
      "         841,  777, 1428,  815, 1349, 1080])}\n",
      "{'input_ids': tensor([[    2,  2841,    16,  ...,     0,     0,     0],\n",
      "        [    2,  4776,    17,  ...,     0,     0,     0],\n",
      "        [    2, 11344, 26380,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  6745, 11173,  ...,     0,     0,     0],\n",
      "        [    2,  6960,  8676,  ...,     0,     0,     0],\n",
      "        [    2,  9393,  1494,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 113,  128, 1845, 1236, 1326,  818, 1849, 1124,  909,  786,  916,  170,\n",
      "        1569, 1642,  783,  366,  594,  535, 1142, 1742,  774, 1801,  846, 1813,\n",
      "         672,  809,  933, 1738, 1192,  446])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 20:16:43 - INFO - tensor(1159)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1035)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1812)\n",
      "2024-11-17 20:16:43 - INFO - tensor(459)\n",
      "2024-11-17 20:16:43 - INFO - tensor(888)\n",
      "2024-11-17 20:16:43 - INFO - tensor(145)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1764)\n",
      "2024-11-17 20:16:43 - INFO - tensor(463)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1709)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1789)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1389)\n",
      "2024-11-17 20:16:43 - INFO - tensor(474)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1858)\n",
      "2024-11-17 20:16:43 - INFO - tensor(493)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1611)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1006)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1233)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1032)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1773)\n",
      "2024-11-17 20:16:43 - INFO - tensor(513)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1112)\n",
      "2024-11-17 20:16:43 - INFO - tensor(536)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1693)\n",
      "2024-11-17 20:16:43 - INFO - tensor(907)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1186)\n",
      "2024-11-17 20:16:43 - INFO - tensor(429)\n",
      "2024-11-17 20:16:43 - INFO - tensor(200)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1720)\n",
      "2024-11-17 20:16:43 - INFO - tensor(698)\n",
      "2024-11-17 20:16:43 - INFO - tensor(885)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1040)\n",
      "2024-11-17 20:16:43 - INFO - tensor(552)\n",
      "2024-11-17 20:16:43 - INFO - tensor(462)\n",
      "2024-11-17 20:16:43 - INFO - tensor(113)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1647)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1584)\n",
      "2024-11-17 20:16:43 - INFO - tensor(574)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1334)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1181)\n",
      "2024-11-17 20:16:43 - INFO - tensor(247)\n",
      "2024-11-17 20:16:43 - INFO - tensor(503)\n",
      "2024-11-17 20:16:43 - INFO - tensor(1668)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  5780,    18,  ...,     0,     0,     0],\n",
      "        [    2,  3704,    16,  ...,     0,     0,     0],\n",
      "        [    2, 10095,    17,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2,  9138,  6907,  ...,     0,     0,     0],\n",
      "        [    2,   293, 17191,  ...,     0,     0,     0],\n",
      "        [    2, 19910,    77,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([1551,  986, 1159, 1035, 1812,  459,  888,  145, 1764,  463, 1709, 1789,\n",
      "        1389,  474, 1858,  493, 1611, 1006, 1233, 1032, 1773,  513, 1112,  536,\n",
      "        1693,  907, 1186,  429,  200, 1720])}\n",
      "{'input_ids': tensor([[    2, 26314,    68,  ...,     0,     0,     0],\n",
      "        [    2,  6745, 12853,  ...,     0,     0,     0],\n",
      "        [    2,  3821,  1560,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    2, 10507,  6263,  ...,     0,     0,     0],\n",
      "        [    2, 15775, 26380,  ...,     0,     0,     0],\n",
      "        [    2, 17533,    13,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([ 698,  885, 1040,  552,  462,  113, 1647, 1584,  574, 1334, 1181,  247,\n",
      "         503, 1668])}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,  batch_size=30, shuffle=True)\n",
    "print(f\" - Number of samples : {len(train_dataloader.dataset)} | Number of batches: {len(train_dataloader)}\")\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset,  batch_size=30, shuffle=True)\n",
    "print(f\" - Number of samples : {len(val_dataloader.dataset)} | Number of batches: {len(val_dataloader)}\")\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dafb484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at AnReu/math_albert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AlbertForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# Load the model\n",
    "model = AlbertForSequenceClassification.from_pretrained(\"AnReu/math_albert\", num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "259c11c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d636e6e21ff24dd1b758cea3714b7ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/748 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billl\\AppData\\Local\\Temp\\ipykernel_6740\\82937343.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(label, dtype=torch.long)\n",
      "2024-11-17 20:22:13 - INFO - tensor(400)\n",
      "2024-11-17 20:22:13 - INFO - tensor(1693)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  4721,    17, 27031,    68,    29, 26380,    18,  3547, 26380,\n",
      "            18,   113,    14,  2116,  1013,    57,    21,   421,   234,    16,\n",
      "         26380,  1489,   184,   378,    42,   293,    71,    14, 19076,    20,\n",
      "         18469,    13,     1,   713,  3318,  3963,    13,     1,    21,  4698,\n",
      "           848,    16,   713,  2984,   713,  3963,    29,    14, 26380,   819,\n",
      "          9011,    71,     3,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [    2,  4721,    17, 27031,    68,    29, 26380,    18, 27031, 26380,\n",
      "            18,   113,    14,  2116,  1013,    57,    21,   421,   234,    16,\n",
      "         26380,  1489,    13,     1,  3033,  3165,   165,    13,     1,    13,\n",
      "             1,  3033,   457,    13,     1,     3,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([ 400, 1693])}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 400 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch)\n\u001b[1;32m---> 25\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\models\\albert\\modeling_albert.py:1179\u001b[0m, in \u001b[0;36mAlbertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1178\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[1;32m-> 1179\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1181\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m BCEWithLogitsLoss()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 400 is out of bounds."
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    for batch in progress_bar:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        print(batch)\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    # Validation loop (optional)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            print(batch)\n",
    "            outputs = model(**batch)\n",
    "            val_loss = outputs.loss\n",
    "            print(f\"Validation loss: {val_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eee863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "logging.info(\"initialize trainer\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "logging.info('training the model')\n",
    "trainer.train()\n",
    "\n",
    "logging.info('evaluate model')\n",
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9738540,
     "sourceId": 82695,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.848234,
   "end_time": "2024-10-11T21:33:31.020578",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-11T21:32:37.172344",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
