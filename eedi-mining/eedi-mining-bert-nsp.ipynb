{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global values\n",
    "train_model=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:27.862782Z",
     "iopub.status.busy": "2024-11-30T19:33:27.862391Z",
     "iopub.status.idle": "2024-11-30T19:33:27.872934Z",
     "shell.execute_reply": "2024-11-30T19:33:27.871633Z",
     "shell.execute_reply.started": "2024-11-30T19:33:27.862739Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 15:36:27 - INFO - starting script\n",
      "[INFO] 2024-12-05 15:36:27,677 >>\ttop of script\n",
      "[INFO] 2024-12-05 15:36:27,677 >>\ttop of script\n",
      "[INFO] 2024-12-05 15:36:27,677 >>\ttop of script\n",
      "[INFO] 2024-12-05 15:36:27,677 >>\ttop of script\n",
      "[INFO] 2024-12-05 15:36:27,677 >>\ttop of script\n",
      "2024-12-05 15:36:27 - INFO - top of script\n"
     ]
    }
   ],
   "source": [
    "import logging \n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logging.info(\"starting script\")\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from logging import getLogger, Formatter, FileHandler, StreamHandler, INFO, DEBUG\n",
    "\n",
    "\n",
    "def create_logger(exp_version):\n",
    "    log_file = (\"{}.log\".format(exp_version))\n",
    "\n",
    "    # logger\n",
    "    logger_ = getLogger(exp_version)\n",
    "    logger_.setLevel(DEBUG)\n",
    "\n",
    "    # formatter\n",
    "    fmr = Formatter(\"[%(levelname)s] %(asctime)s >>\\t%(message)s\")\n",
    "\n",
    "    # file handler\n",
    "    fh = FileHandler(log_file)\n",
    "    fh.setLevel(DEBUG)\n",
    "    fh.setFormatter(fmr)\n",
    "\n",
    "    # stream handler\n",
    "    ch = StreamHandler()\n",
    "    ch.setLevel(INFO)\n",
    "    ch.setFormatter(fmr)\n",
    "\n",
    "    logger_.addHandler(fh)\n",
    "    logger_.addHandler(ch)\n",
    "\n",
    "\n",
    "def get_logger(exp_version):\n",
    "    return getLogger(exp_version)\n",
    "\n",
    "VERSION = \"001\" \n",
    "create_logger(VERSION)\n",
    "get_logger(VERSION).info(\"top of script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:27.875417Z",
     "iopub.status.busy": "2024-11-30T19:33:27.874953Z",
     "iopub.status.idle": "2024-11-30T19:33:28.239861Z",
     "shell.execute_reply": "2024-11-30T19:33:28.238601Z",
     "shell.execute_reply.started": "2024-11-30T19:33:27.875369Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2024-12-05 15:36:27,851 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\misconception_mapping.csv\n",
      "[INFO] 2024-12-05 15:36:27,851 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\misconception_mapping.csv\n",
      "[INFO] 2024-12-05 15:36:27,851 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\misconception_mapping.csv\n",
      "[INFO] 2024-12-05 15:36:27,851 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\misconception_mapping.csv\n",
      "[INFO] 2024-12-05 15:36:27,851 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\misconception_mapping.csv\n",
      "2024-12-05 15:36:27 - INFO - C:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\misconception_mapping.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\sample_submission.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\sample_submission.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\sample_submission.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\sample_submission.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\sample_submission.csv\n",
      "2024-12-05 15:36:27 - INFO - C:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\sample_submission.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\test.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\test.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\test.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\test.csv\n",
      "[INFO] 2024-12-05 15:36:27,862 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\test.csv\n",
      "2024-12-05 15:36:27 - INFO - C:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\test.csv\n",
      "[INFO] 2024-12-05 15:36:27,877 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\train.csv\n",
      "[INFO] 2024-12-05 15:36:27,877 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\train.csv\n",
      "[INFO] 2024-12-05 15:36:27,877 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\train.csv\n",
      "[INFO] 2024-12-05 15:36:27,877 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\train.csv\n",
      "[INFO] 2024-12-05 15:36:27,877 >>\tC:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\train.csv\n",
      "2024-12-05 15:36:27 - INFO - C:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\train.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\\\misconception_mapping.csv', 'C:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\\\sample_submission.csv', 'C:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\\\test.csv', 'C:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics\\\\train.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "files = []\n",
    "data_dir = 'C:/ai_ml/kaggle/eedi-mining/eedi-mining-misconceptions-in-mathematics'\n",
    "miscon_file_index = 0\n",
    "train_file_index = 3\n",
    "test_file_index = 2\n",
    "# on kaggle\n",
    "# data_dir = '/kaggle/input'\n",
    "#miscon_file_index = 1\n",
    "#train_file_index = 2\n",
    "#test_file_index = 3\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(data_dir):\n",
    "    for filename in filenames:\n",
    "        get_logger(VERSION).info(os.path.join(dirname, filename))\n",
    "        files.append(os.path.join(dirname, filename))\n",
    "print(files)\n",
    "misconceptions_filename = files[miscon_file_index]\n",
    "train_filename = files[train_file_index]\n",
    "test_filename = files[test_file_index]\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File and Field Information\n",
    "### [train/test].csv\n",
    "\n",
    "* QuestionId - Unique question identifier (int).\n",
    "* ConstructId - Unique construct identifier (int) .\n",
    "* ConstructName - Most granular level of knowledge related to question (str).\n",
    "* CorrectAnswer - A, B, C or D (char).\n",
    "* SubjectId - Unique subject identifier (int).\n",
    "* SubjectName - More general context than the construct (str).\n",
    "* QuestionText - Question text extracted from the question image using human-in-the-loop OCR (str) .\n",
    "* Answer[A/B/C/D]Text - Answer option A text extracted from the question image using human-in-the-loop OCR (str).\n",
    "* Misconception[A/B/C/D]Id - Unique misconception identifier (int). Ground truth labels in train.csv; your task is to predict these labels for test.csv.\n",
    "\n",
    "### misconception_mapping.csv\n",
    "maps MisconceptionId to its MisconceptionName\n",
    "\n",
    "### sample_submission.csv\n",
    "A submission file in the correct format.\n",
    "* QuestionId_Answer - Each question has three incorrect answers for which need you predict the MisconceptionId.\n",
    "* MisconceptionId - You can predict up to 25 values, space delimited.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.242955Z",
     "iopub.status.busy": "2024-11-30T19:33:28.242186Z",
     "iopub.status.idle": "2024-11-30T19:33:28.315291Z",
     "shell.execute_reply": "2024-11-30T19:33:28.313987Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.242885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>AnswerAText</th>\n",
       "      <th>AnswerBText</th>\n",
       "      <th>AnswerCText</th>\n",
       "      <th>AnswerDText</th>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <th>MisconceptionDId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>856</td>\n",
       "      <td>Use the order of operations to carry out calcu...</td>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>A</td>\n",
       "      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...</td>\n",
       "      <td>\\( 3 \\times(2+4)-5 \\)</td>\n",
       "      <td>\\( 3 \\times 2+(4-5) \\)</td>\n",
       "      <td>\\( 3 \\times(2+4-5) \\)</td>\n",
       "      <td>Does not need brackets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1612</td>\n",
       "      <td>Simplify an algebraic fraction by factorising ...</td>\n",
       "      <td>1077</td>\n",
       "      <td>Simplifying Algebraic Fractions</td>\n",
       "      <td>D</td>\n",
       "      <td>Simplify the following, if possible: \\( \\frac{...</td>\n",
       "      <td>\\( m+1 \\)</td>\n",
       "      <td>\\( m+2 \\)</td>\n",
       "      <td>\\( m-1 \\)</td>\n",
       "      <td>Does not simplify</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2142.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2774</td>\n",
       "      <td>Calculate the range from a list of data</td>\n",
       "      <td>339</td>\n",
       "      <td>Range and Interquartile Range from a List of Data</td>\n",
       "      <td>B</td>\n",
       "      <td>Tom and Katie are discussing the \\( 5 \\) plant...</td>\n",
       "      <td>Only\\nTom</td>\n",
       "      <td>Only\\nKatie</td>\n",
       "      <td>Both Tom and Katie</td>\n",
       "      <td>Neither is correct</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>1073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2377</td>\n",
       "      <td>Recall and use the intersecting diagonals prop...</td>\n",
       "      <td>88</td>\n",
       "      <td>Properties of Quadrilaterals</td>\n",
       "      <td>C</td>\n",
       "      <td>The angles highlighted on this rectangle with ...</td>\n",
       "      <td>acute</td>\n",
       "      <td>obtuse</td>\n",
       "      <td>\\( 90^{\\circ} \\)</td>\n",
       "      <td>Not enough information</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3387</td>\n",
       "      <td>Substitute positive integer values into formul...</td>\n",
       "      <td>67</td>\n",
       "      <td>Substitution into Formula</td>\n",
       "      <td>A</td>\n",
       "      <td>The equation \\( f=3 r^{2}+3 \\) is used to find...</td>\n",
       "      <td>\\( 30 \\)</td>\n",
       "      <td>\\( 27 \\)</td>\n",
       "      <td>\\( 51 \\)</td>\n",
       "      <td>\\( 24 \\)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1818.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QuestionId  ConstructId                                      ConstructName  \\\n",
       "0           0          856  Use the order of operations to carry out calcu...   \n",
       "1           1         1612  Simplify an algebraic fraction by factorising ...   \n",
       "2           2         2774            Calculate the range from a list of data   \n",
       "3           3         2377  Recall and use the intersecting diagonals prop...   \n",
       "4           4         3387  Substitute positive integer values into formul...   \n",
       "\n",
       "   SubjectId                                        SubjectName CorrectAnswer  \\\n",
       "0         33                                             BIDMAS             A   \n",
       "1       1077                    Simplifying Algebraic Fractions             D   \n",
       "2        339  Range and Interquartile Range from a List of Data             B   \n",
       "3         88                       Properties of Quadrilaterals             C   \n",
       "4         67                          Substitution into Formula             A   \n",
       "\n",
       "                                        QuestionText            AnswerAText  \\\n",
       "0  \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets ...  \\( 3 \\times(2+4)-5 \\)   \n",
       "1  Simplify the following, if possible: \\( \\frac{...              \\( m+1 \\)   \n",
       "2  Tom and Katie are discussing the \\( 5 \\) plant...              Only\\nTom   \n",
       "3  The angles highlighted on this rectangle with ...                  acute   \n",
       "4  The equation \\( f=3 r^{2}+3 \\) is used to find...               \\( 30 \\)   \n",
       "\n",
       "              AnswerBText            AnswerCText             AnswerDText  \\\n",
       "0  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)  Does not need brackets   \n",
       "1               \\( m+2 \\)              \\( m-1 \\)       Does not simplify   \n",
       "2             Only\\nKatie     Both Tom and Katie      Neither is correct   \n",
       "3                  obtuse       \\( 90^{\\circ} \\)  Not enough information   \n",
       "4                \\( 27 \\)               \\( 51 \\)                \\( 24 \\)   \n",
       "\n",
       "   MisconceptionAId  MisconceptionBId  MisconceptionCId  MisconceptionDId  \n",
       "0               NaN               NaN               NaN            1672.0  \n",
       "1            2142.0             143.0            2142.0               NaN  \n",
       "2            1287.0               NaN            1287.0            1073.0  \n",
       "3            1180.0            1180.0               NaN            1180.0  \n",
       "4               NaN               NaN               NaN            1818.0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_filename)\n",
    "train_data_orig = train_data.copy()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.317292Z",
     "iopub.status.busy": "2024-11-30T19:33:28.316813Z",
     "iopub.status.idle": "2024-11-30T19:33:28.331231Z",
     "shell.execute_reply": "2024-11-30T19:33:28.329836Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.317244Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data shape\n",
      "rows 3\n",
      "columns 11\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_filename)\n",
    "test_data_orig = test_data.copy()\n",
    "test_data.head()\n",
    "print (\"test_data shape\")\n",
    "print(\"rows\", test_data.shape[0])\n",
    "print(\"columns\",test_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get misconception data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.335159Z",
     "iopub.status.busy": "2024-11-30T19:33:28.334678Z",
     "iopub.status.idle": "2024-11-30T19:33:28.360948Z",
     "shell.execute_reply": "2024-11-30T19:33:28.359708Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.335112Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MisconceptionId</th>\n",
       "      <th>MisconceptionName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Does not know that angles in a triangle sum to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Uses dividing fractions method for multiplying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Believes there are 100 degrees in a full turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Thinks a quadratic without a non variable term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Believes addition of terms and powers of terms...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MisconceptionId                                  MisconceptionName\n",
       "0                0  Does not know that angles in a triangle sum to...\n",
       "1                1  Uses dividing fractions method for multiplying...\n",
       "2                2      Believes there are 100 degrees in a full turn\n",
       "3                3  Thinks a quadratic without a non variable term...\n",
       "4                4  Believes addition of terms and powers of terms..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miscon_data = pd.read_csv(misconceptions_filename)\n",
    "miscon_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.363158Z",
     "iopub.status.busy": "2024-11-30T19:33:28.362686Z",
     "iopub.status.idle": "2024-11-30T19:33:28.369932Z",
     "shell.execute_reply": "2024-11-30T19:33:28.368694Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.363111Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miscon_data shape\n",
      "rows 2587\n",
      "columns 2\n"
     ]
    }
   ],
   "source": [
    "print (\"miscon_data shape\")\n",
    "print(\"rows\", miscon_data.shape[0])\n",
    "print(\"columns\",miscon_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.371812Z",
     "iopub.status.busy": "2024-11-30T19:33:28.371294Z",
     "iopub.status.idle": "2024-11-30T19:33:28.420352Z",
     "shell.execute_reply": "2024-11-30T19:33:28.419198Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.371764Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163  different subject groups\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>AnswerAText</th>\n",
       "      <th>AnswerBText</th>\n",
       "      <th>AnswerCText</th>\n",
       "      <th>AnswerDText</th>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <th>MisconceptionDId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>Linear Equations</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171</td>\n",
       "      <td>Linear Sequences (nth term)</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>BIDMAS</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>Quadratic Equations</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>Area of Simple Shapes</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SubjectId                  SubjectName  QuestionId  ConstructId  \\\n",
       "0         64             Linear Equations          53           53   \n",
       "1        171  Linear Sequences (nth term)          44           44   \n",
       "2         33                       BIDMAS          37           37   \n",
       "3         65          Quadratic Equations          36           36   \n",
       "4         75        Area of Simple Shapes          36           36   \n",
       "\n",
       "   ConstructName  CorrectAnswer  QuestionText  AnswerAText  AnswerBText  \\\n",
       "0             53             53            53           53           53   \n",
       "1             44             44            44           44           44   \n",
       "2             37             37            37           37           37   \n",
       "3             36             36            36           36           36   \n",
       "4             36             36            36           36           36   \n",
       "\n",
       "   AnswerCText  AnswerDText  MisconceptionAId  MisconceptionBId  \\\n",
       "0           53           53                23                32   \n",
       "1           44           44                28                20   \n",
       "2           37           37                20                21   \n",
       "3           36           36                18                17   \n",
       "4           36           36                22                26   \n",
       "\n",
       "   MisconceptionCId  MisconceptionDId  \n",
       "0                30                27  \n",
       "1                21                19  \n",
       "2                23                24  \n",
       "3                25                14  \n",
       "4                23                24  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_groups = train_data.groupby([\"SubjectId\",\"SubjectName\"]).count().sort_values('QuestionId',ascending=False).reset_index()\n",
    "print(subject_groups.shape[0], \" different subject groups\")\n",
    "subject_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.422364Z",
     "iopub.status.busy": "2024-11-30T19:33:28.422017Z",
     "iopub.status.idle": "2024-11-30T19:33:28.447183Z",
     "shell.execute_reply": "2024-11-30T19:33:28.445880Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.422331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentages of null values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <td>734</td>\n",
       "      <td>39.272338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <td>751</td>\n",
       "      <td>40.181915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <td>789</td>\n",
       "      <td>42.215088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MisconceptionDId</th>\n",
       "      <td>832</td>\n",
       "      <td>44.515784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count  Percentage\n",
       "MisconceptionAId    734   39.272338\n",
       "MisconceptionBId    751   40.181915\n",
       "MisconceptionCId    789   42.215088\n",
       "MisconceptionDId    832   44.515784"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"percentages of null values\")\n",
    "pd.DataFrame({'Count':train_data.isnull().sum()[train_data.isnull().sum()>0],'Percentage':(train_data.isnull().sum()[train_data.isnull().sum()>0]/train_data.shape[0])*100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.448802Z",
     "iopub.status.busy": "2024-11-30T19:33:28.448459Z",
     "iopub.status.idle": "2024-11-30T19:33:28.473173Z",
     "shell.execute_reply": "2024-11-30T19:33:28.471734Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.448768Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(482, 15)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# records where more than one misconception id is missing\n",
    "missing_a_misconception = train_data[(train_data.CorrectAnswer == \"A\") & (train_data.MisconceptionBId.isnull() | train_data.MisconceptionCId.isnull()  | train_data.MisconceptionDId.isnull()) ]\n",
    "print(missing_a_misconception.shape)\n",
    "missing_a_misconception.head()\n",
    "train_data[(train_data.CorrectAnswer == \"A\")].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.476111Z",
     "iopub.status.busy": "2024-11-30T19:33:28.475592Z",
     "iopub.status.idle": "2024-11-30T19:33:28.502822Z",
     "shell.execute_reply": "2024-11-30T19:33:28.501598Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.476062Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QuestionId</th>\n",
       "      <th>ConstructId</th>\n",
       "      <th>ConstructName</th>\n",
       "      <th>SubjectId</th>\n",
       "      <th>SubjectName</th>\n",
       "      <th>CorrectAnswer</th>\n",
       "      <th>QuestionText</th>\n",
       "      <th>AnswerAText</th>\n",
       "      <th>AnswerBText</th>\n",
       "      <th>AnswerCText</th>\n",
       "      <th>AnswerDText</th>\n",
       "      <th>MisconceptionAId</th>\n",
       "      <th>MisconceptionBId</th>\n",
       "      <th>MisconceptionCId</th>\n",
       "      <th>MisconceptionDId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1414</td>\n",
       "      <td>Expand products of three binomials in the form...</td>\n",
       "      <td>335</td>\n",
       "      <td>Expanding Triple Brackets and more</td>\n",
       "      <td>B</td>\n",
       "      <td>John is expanding these three brackets:\\n\\(\\n(...</td>\n",
       "      <td>\\( +6 x^{2} \\)</td>\n",
       "      <td>\\( \\begin{array}{l}+6 x^{2} \\\\ -3 x^{2} \\\\ +5 ...</td>\n",
       "      <td>\\( \\begin{array}{l}+6 x^{2} \\\\ +3 x^{2} \\\\ +5 ...</td>\n",
       "      <td>\\( \\begin{array}{l}+6 x^{2} \\\\ -3 x^{2} \\\\ -5 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>583.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>3065</td>\n",
       "      <td>Convert from hours to minutes</td>\n",
       "      <td>209</td>\n",
       "      <td>Time</td>\n",
       "      <td>B</td>\n",
       "      <td>Hannah's journey to camp is \\( 3 \\) hours and ...</td>\n",
       "      <td>\\( 196 \\) minutes</td>\n",
       "      <td>\\( 18 \\) minutes</td>\n",
       "      <td>\\( 102 \\) minutes</td>\n",
       "      <td>\\( 12 \\) minutes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>261</td>\n",
       "      <td>Carry out missing number subtraction problems ...</td>\n",
       "      <td>211</td>\n",
       "      <td>Adding and Subtracting Negative Numbers</td>\n",
       "      <td>B</td>\n",
       "      <td>![Number line with -12 and -7 marked. Starting...</td>\n",
       "      <td>\\( -7 \\)</td>\n",
       "      <td>\\( -5 \\)</td>\n",
       "      <td>\\( -2 \\)</td>\n",
       "      <td>\\( -6 \\)</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1824.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2306</td>\n",
       "      <td>Given the volume of a cuboid, work out missing...</td>\n",
       "      <td>189</td>\n",
       "      <td>Volume of Prisms</td>\n",
       "      <td>B</td>\n",
       "      <td>The volume of this cuboid is \\( 30 \\mathrm{~cm...</td>\n",
       "      <td>\\( 6 \\mathrm{~cm} \\)</td>\n",
       "      <td>\\( 5 \\mathrm{~cm} \\)</td>\n",
       "      <td>\\( 4 \\mathrm{~cm} \\)</td>\n",
       "      <td>\\( 25 \\mathrm{~cm} \\)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1434</td>\n",
       "      <td>Factorise a quadratic expression in the form a...</td>\n",
       "      <td>53</td>\n",
       "      <td>Factorising into a Double Bracket</td>\n",
       "      <td>B</td>\n",
       "      <td>Step 1: Factorise the following expression\\n\\n...</td>\n",
       "      <td>\\( (3 x+2)(3 x+1) \\)</td>\n",
       "      <td>\\( (3 x+2)(x+1) \\)</td>\n",
       "      <td>Cannot be factorised</td>\n",
       "      <td>\\( (3 x+1)(x+2) \\)</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    QuestionId  ConstructId  \\\n",
       "10          10         1414   \n",
       "13          13         3065   \n",
       "18          18          261   \n",
       "20          20         2306   \n",
       "21          21         1434   \n",
       "\n",
       "                                        ConstructName  SubjectId  \\\n",
       "10  Expand products of three binomials in the form...        335   \n",
       "13                      Convert from hours to minutes        209   \n",
       "18  Carry out missing number subtraction problems ...        211   \n",
       "20  Given the volume of a cuboid, work out missing...        189   \n",
       "21  Factorise a quadratic expression in the form a...         53   \n",
       "\n",
       "                                SubjectName CorrectAnswer  \\\n",
       "10       Expanding Triple Brackets and more             B   \n",
       "13                                     Time             B   \n",
       "18  Adding and Subtracting Negative Numbers             B   \n",
       "20                         Volume of Prisms             B   \n",
       "21        Factorising into a Double Bracket             B   \n",
       "\n",
       "                                         QuestionText           AnswerAText  \\\n",
       "10  John is expanding these three brackets:\\n\\(\\n(...        \\( +6 x^{2} \\)   \n",
       "13  Hannah's journey to camp is \\( 3 \\) hours and ...     \\( 196 \\) minutes   \n",
       "18  ![Number line with -12 and -7 marked. Starting...              \\( -7 \\)   \n",
       "20  The volume of this cuboid is \\( 30 \\mathrm{~cm...  \\( 6 \\mathrm{~cm} \\)   \n",
       "21  Step 1: Factorise the following expression\\n\\n...  \\( (3 x+2)(3 x+1) \\)   \n",
       "\n",
       "                                          AnswerBText  \\\n",
       "10  \\( \\begin{array}{l}+6 x^{2} \\\\ -3 x^{2} \\\\ +5 ...   \n",
       "13                                   \\( 18 \\) minutes   \n",
       "18                                           \\( -5 \\)   \n",
       "20                               \\( 5 \\mathrm{~cm} \\)   \n",
       "21                                 \\( (3 x+2)(x+1) \\)   \n",
       "\n",
       "                                          AnswerCText  \\\n",
       "10  \\( \\begin{array}{l}+6 x^{2} \\\\ +3 x^{2} \\\\ +5 ...   \n",
       "13                                  \\( 102 \\) minutes   \n",
       "18                                           \\( -2 \\)   \n",
       "20                               \\( 4 \\mathrm{~cm} \\)   \n",
       "21                               Cannot be factorised   \n",
       "\n",
       "                                          AnswerDText  MisconceptionAId  \\\n",
       "10  \\( \\begin{array}{l}+6 x^{2} \\\\ -3 x^{2} \\\\ -5 ...               NaN   \n",
       "13                                   \\( 12 \\) minutes               NaN   \n",
       "18                                           \\( -6 \\)            2179.0   \n",
       "20                              \\( 25 \\mathrm{~cm} \\)               NaN   \n",
       "21                                 \\( (3 x+1)(x+2) \\)            2240.0   \n",
       "\n",
       "    MisconceptionBId  MisconceptionCId  MisconceptionDId  \n",
       "10               NaN             583.0               NaN  \n",
       "13               NaN             161.0               NaN  \n",
       "18               NaN               NaN            1824.0  \n",
       "20               NaN               NaN            1984.0  \n",
       "21               NaN               NaN               NaN  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_b_misconpception = train_data[(train_data.CorrectAnswer == \"B\") & (train_data.MisconceptionAId.isnull() | train_data.MisconceptionCId.isnull()) ]\n",
    "missing_b_misconpception.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update data to prepare for creating vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.506841Z",
     "iopub.status.busy": "2024-11-30T19:33:28.506443Z",
     "iopub.status.idle": "2024-11-30T19:33:28.513628Z",
     "shell.execute_reply": "2024-11-30T19:33:28.512236Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.506803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# clean up question\n",
    "# train_data['CleanQuestion'] = train_data['QuestionText'].replace('\\n',' ',regex=True)\n",
    "\n",
    "# create new data frame with just misconceptions\n",
    "# Create a new empty DataFrame\n",
    "miscon_model = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:33:28.516490Z",
     "iopub.status.busy": "2024-11-30T19:33:28.516002Z",
     "iopub.status.idle": "2024-11-30T19:38:05.015769Z",
     "shell.execute_reply": "2024-11-30T19:38:05.014426Z",
     "shell.execute_reply.started": "2024-11-30T19:33:28.516438Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:52: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:52: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\billl\\AppData\\Local\\Temp\\ipykernel_10504\\1767391032.py:52: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  text = \"Here's an example: \\int_0^{\\infty} e^{-x^2} dx.\\n Let's clean it up!\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heres an example \\int_0^{\\infty} e^{x^2} dx lets clean it up\n",
      "['use the order of operations to carry out calculations involving powers \\\\ 3 \\\\times 245 \\\\ where do the brackets need to go to make the answer equal \\\\ 13 \\\\ does not need brackets', 'Confuses the order of operations, believes addition comes before multiplication']\n",
      "['simplify an algebraic fraction by factorising the numerator simplify the following if possible \\\\ \\\\frac{m^{2}2 m3}{m3} \\\\ \\\\ m1 \\\\', 'Does not know that to factorise a quadratic expression, to find two numbers that add to give the coefficient of the x term, and multiply to give the non variable term']\n",
      "['calculate the range from a list of data tom and katie are discussing the \\\\ 5 \\\\ plants with these heights \\\\ 24 \\\\mathrm{cm} 17 \\\\mathrm{cm} 42 \\\\mathrm{cm} 26 \\\\mathrm{cm} 13 \\\\mathrm{cm} \\\\ tom says if all the plants were cut in half the range wouldnt change katie says if all the plants grew by \\\\ 3 \\\\mathrm{cm} \\\\ each the range wouldnt change who do you agree with neither is correct', 'Believes if you add the same value to all numbers in the dataset the range will change']\n",
      "['recall and use the intersecting diagonals properties of a rectangle the angles highlighted on this rectangle with different length sides can never be a rectangle with the diagonals drawn in the angle on the right hand side at the centre is highlighted in red and the angle at the bottom at the centre is highlighted in yellow not enough information', 'Does not know the properties of a rectangle']\n",
      "['substitute positive integer values into formulae involving powers or roots the equation \\\\ f3 r^{2}3 \\\\ is used to find values in the table below what is the value covered by the star \\\\begin{tabular}{ccccc} \\\\hline\\\\ r \\\\ \\\\ 1 \\\\ \\\\ 2 \\\\ \\\\ 3 \\\\ \\\\ 4 \\\\ \\\\\\\\ \\\\hline\\\\ f \\\\ \\\\ 6 \\\\ \\\\ 15 \\\\ \\\\ \\\\color{gold}\\\\bigstar \\\\ \\\\\\\\ \\\\hline \\\\end{tabular} \\\\ 24 \\\\', 'Thinks you can find missing values in a given table by treating the row as linear and adding on the difference between the first two values given.']\n",
      "['identify a unit of area james has answered a question on the area of a trapezium and got an answer of \\\\ 54 \\\\ behind the star he has written the units that he used \\\\ 54 \\\\ \\\\bigstar \\\\ which of the following units could be correct \\\\ \\\\mathrm{km}^{3} \\\\', 'Does not know units of area should be squared']\n",
      "['convert two digit integer percentages to fractions convert this percentage to a fraction \\\\ 62 \\\\ \\\\ none of these', 'Does not understand a percentage is out of 100']\n",
      "['divide decimals by 10 \\\\ 432 \\\\div 10 \\\\ \\\\ 4302 \\\\', 'When dividing a decimal by a multiple of 10, just divides the fractional place values']\n",
      "['subtract proper fractions with different denominators which do not share a common factor \\\\ \\\\frac{4}{5}\\\\frac{1}{3}\\\\frac{\\\\bigstar}{15} \\\\ what should replace the star \\\\ 3 \\\\', 'Does not find a common denominator when adding/subtracting fractions']\n",
      "['identify horizontal translations in the form fx for nontrigonometric functions what transformation maps the graph of \\\\yfx \\\\ to the graph of \\\\ yfx3 \\\\ translation by vector \\\\ \\\\left\\\\begin{array}{r} 3 \\\\\\\\ 0 \\\\end{array}\\\\right \\\\', 'Believes f(x) + a translates the function right a units']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# convert latext formatting to text\n",
    "from pylatexenc.latex2text import LatexNodes2Text\n",
    "import pylatexenc\n",
    "# Convert LaTeX to plain text\n",
    "# Function to convert LaTeX to text\n",
    "def latex_to_text(latex_string):\n",
    "    return LatexNodes2Text().latex_to_text(latex_string)\n",
    "\"\"\"\n",
    "\n",
    "# repolace names with variables to get consistency on vectors\n",
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "# for running locally, need to do\n",
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to replace all detected names with unique variables\n",
    "def replace_names_with_variables(text):\n",
    "    doc = nlp(text)\n",
    "    name_counter = 1\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            var_name = f\"NAME{name_counter}\"\n",
    "            text = text.replace(ent.text, var_name)\n",
    "            name_counter += 1\n",
    "    return text\n",
    "\n",
    "#def clean_math_text(text):\n",
    "    # clean_text = latex_to_text(text)\n",
    "    # clean_text = replace_names_with_variables(clean_text)\n",
    "    # remove new line and other characters\n",
    "    # print('before',clean_text)\n",
    "    #clean_text = clean_text.replace('\\n',' ')\n",
    "    # print('after', clean_text)\n",
    "    \n",
    "    #return clean_text \n",
    "import re\n",
    "\n",
    "def clean_math_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters (keeping LaTeX symbols)\n",
    "    text = text.replace(\"\\\\n\", \" \")\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\\\{}^_]', '', text)\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Example text\n",
    "text = \"Here's an example: \\int_0^{\\infty} e^{-x^2} dx.\\n Let's clean it up!\"\n",
    "\n",
    "# Clean the text\n",
    "cleaned_text = clean_math_text(text)\n",
    "print(cleaned_text)\n",
    "\n",
    "\n",
    "# remove special characters like new line\n",
    "#miscon_model['subjectName'] = train_data.SubjectName\n",
    "#miscon_model['constructName'] = train_data.ConstructName\n",
    "#miscon_model['question'] = train_data['QuestionText'].apply(clean_math_text)\n",
    "#  Creating the flattened DataFrame\n",
    "import math\n",
    "flattened_data = []\n",
    "next_sentence =[]\n",
    "next_sentence_val = []\n",
    "pairs=[]\n",
    "val_pairs = []\n",
    "miscon_ids_used = {}\n",
    "MAX_LEN=1400\n",
    "def add_other_misconceptions_as_label_1(problem_and_wrong_answer, misconception_id_in):\n",
    "    # dataframe of all misconception ids except this on\n",
    "    all_but_one = miscon_data[miscon_data['MisconceptionId'] != misconception_id_in]\n",
    "    all_but_one = all_but_one.sample(n=50, replace=True, random_state=1)\n",
    "    for index0, row0 in all_but_one.iterrows():\n",
    "        #print(\"row0\",row0.MisconceptionName)\n",
    "        next_sentence.append({'problem_and_wrong_answer': problem_and_wrong_answer,\"misconception_text\": row0.MisconceptionName, \"misconception_id\": row0.MisconceptionId,\"label\":1})\n",
    "\n",
    "for index, row in train_data.iterrows():\n",
    "    # put incorrect answer A into row\n",
    "    # print (\"a id\",row.MisconceptionAId)\n",
    "\n",
    "    if ((row.CorrectAnswer != \"A\") & (math.isnan(row.MisconceptionAId) == False)):\n",
    "        misconception_text_row = miscon_data[(miscon_data.MisconceptionId==row.MisconceptionAId)]\n",
    "        #print(type(misconception_text_row))\n",
    "        #print(misconception_text_row.iloc[0,1])\n",
    "        misconception_id = row.MisconceptionAId\n",
    "        formatted_answer = clean_math_text(row['AnswerAText'])\n",
    "        #flattened_data.append({'subjectName': row['SubjectName'], 'constructName': row['ConstructName'], 'latex_formatted_question': row['QuestionText'], 'question': clean_math_text(row['QuestionText']), 'latex_formatted_wrongAnswer': row['AnswerAText'], 'wrongAnswer': clean_math_text(row['AnswerAText']), 'misconception': misconception_row.MisconceptionName})\n",
    "    if ((row.CorrectAnswer != \"B\") & (math.isnan(row.MisconceptionBId)==False)):\n",
    "        misconception_text_row = miscon_data[(miscon_data.MisconceptionId==row.MisconceptionBId)]\n",
    "        misconception_id = row.MisconceptionBId\n",
    "        formatted_answer= clean_math_text(row['AnswerBText'])\n",
    "        # flattened_data.append({'subjectName': row['SubjectName']}, 'constructName': row['ConstructName'], 'latex_formatted_question': row['QuestionText'], 'question': clean_math_text(row['QuestionText']), 'latext_formatted_wrongAnswer': row['AnswerBText'], 'wrongAnswer': clean_math_text(row['AnswerBText']), 'misconception': misconception_row.MisconceptionName})\n",
    "    if ((row.CorrectAnswer != \"C\") & (math.isnan(row.MisconceptionCId) ==False)):\n",
    "        misconception_text_row = miscon_data[(miscon_data.MisconceptionId==row.MisconceptionCId)]\n",
    "        misconception_id = row.MisconceptionCId\n",
    "        formatted_answer = clean_math_text(row['AnswerCText'])        \n",
    "        # flattened_data.append({'subjectName': row['SubjectName'], 'constructName': row['ConstructName'], 'latex_formatted_question': row['QuestionText'], 'question': clean_math_text(row['QuestionText']), 'latext_formatted_wrongAnswer': row['AnswerCText'], 'wrongAnswer': clean_math_text(row['AnswerCText']), 'misconception': misconception_row.MisconceptionName})\n",
    "    if ((row.CorrectAnswer != \"D\") & (math.isnan(row.MisconceptionDId) == False)):\n",
    "        misconception_text_row = miscon_data[(miscon_data.MisconceptionId==row.MisconceptionDId)]\n",
    "        misconception_id = row.MisconceptionDId\n",
    "        formatted_answer =  clean_math_text(row['AnswerDText'])\n",
    "        # flattened_data.append({'subjectName': row['SubjectName'], 'constructName': row['ConstructName'], 'latex_formatted_question': row['QuestionText'], 'question': clean_math_text(row['QuestionText']), 'latext_formatted_wrongAnswer': row['AnswerDText'], 'wrongAnswer': clean_math_text(row['AnswerDText']), 'misconception': misconception_row.MisconceptionName})\n",
    "    problem_and_wrong_answer = f\"{clean_math_text(row['ConstructName'])} {clean_math_text(row['QuestionText'])} {formatted_answer}\"\n",
    "    misconception_text= misconception_text_row.iloc[0,1]\n",
    "    qa_pairs = []\n",
    "    qa_pairs.append(' '.join(problem_and_wrong_answer.split()[:MAX_LEN]))\n",
    "    qa_pairs.append(' '.join(misconception_text.split()[:MAX_LEN]))\n",
    "    if (index < 10):\n",
    "        print(qa_pairs)\n",
    "    \n",
    "    misconception_id = misconception_text_row.iloc[0,0]\n",
    "    if misconception_id in miscon_ids_used:\n",
    "        miscon_ids_used[misconception_id] += 1\n",
    "    else:\n",
    "        miscon_ids_used[misconception_id] = 1\n",
    "    if (miscon_ids_used[misconception_id] <= 2):\n",
    "        pairs.append(qa_pairs)\n",
    "    else:\n",
    "        val_pairs.append(qa_pairs)\n",
    "\n",
    "    flattened_data.append({'text': f\"{clean_math_text(row['SubjectName'])} {clean_math_text(row['ConstructName'])} {clean_math_text(row['QuestionText'])} {formatted_answer}\", \"label\": int(misconception_id)})\n",
    "    \n",
    "    next_sentence.append({'problem_and_wrong_answer': problem_and_wrong_answer,\"misconception_text\": misconception_text_row.iloc[0,1], \"misconception_id\": misconception_text_row.iloc[0,0],\"label\":0})\n",
    "    #add_other_misconceptions_as_label_1(problem_and_wrong_answer, misconception_id)\n",
    "flattened_df = pd.DataFrame(flattened_data)\n",
    "# Sort by the 'label' column in ascending order \n",
    "flattened_df = flattened_df.sort_values(by='label')\n",
    "flattened_df = flattened_df.reset_index(drop = True)\n",
    "\n",
    "next_sentence_df = pd.DataFrame(next_sentence)\n",
    "next_sentence_df['qlength'] = next_sentence_df['problem_and_wrong_answer'].str.len()\n",
    "next_sentence_df['mlength'] = next_sentence_df['misconception_text'].str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:40:05.440951Z",
     "iopub.status.busy": "2024-11-30T19:40:05.440396Z",
     "iopub.status.idle": "2024-11-30T19:40:05.451690Z",
     "shell.execute_reply": "2024-11-30T19:40:05.450352Z",
     "shell.execute_reply.started": "2024-11-30T19:40:05.440886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angles in triangles find missing angles in a s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>measuring angles identify the number of degree...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>factorising into a single bracket factorise a ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simplifying expressions by collecting like ter...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simplifying expressions by collecting like ter...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  angles in triangles find missing angles in a s...      0\n",
       "1  measuring angles identify the number of degree...      2\n",
       "2  factorising into a single bracket factorise a ...      3\n",
       "3  simplifying expressions by collecting like ter...      4\n",
       "4  simplifying expressions by collecting like ter...      4"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T19:41:46.019936Z",
     "iopub.status.busy": "2024-11-30T19:41:46.019467Z",
     "iopub.status.idle": "2024-11-30T19:41:46.033726Z",
     "shell.execute_reply": "2024-11-30T19:41:46.032358Z",
     "shell.execute_reply.started": "2024-11-30T19:41:46.019875Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1869, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_and_wrong_answer</th>\n",
       "      <th>misconception_text</th>\n",
       "      <th>misconception_id</th>\n",
       "      <th>label</th>\n",
       "      <th>qlength</th>\n",
       "      <th>mlength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>use the order of operations to carry out calcu...</td>\n",
       "      <td>Confuses the order of operations, believes add...</td>\n",
       "      <td>1672</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>simplify an algebraic fraction by factorising ...</td>\n",
       "      <td>Does not know that to factorise a quadratic ex...</td>\n",
       "      <td>2142</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calculate the range from a list of data tom an...</td>\n",
       "      <td>Believes if you add the same value to all numb...</td>\n",
       "      <td>1073</td>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recall and use the intersecting diagonals prop...</td>\n",
       "      <td>Does not know the properties of a rectangle</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>substitute positive integer values into formul...</td>\n",
       "      <td>Thinks you can find missing values in a given ...</td>\n",
       "      <td>1818</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            problem_and_wrong_answer  \\\n",
       "0  use the order of operations to carry out calcu...   \n",
       "1  simplify an algebraic fraction by factorising ...   \n",
       "2  calculate the range from a list of data tom an...   \n",
       "3  recall and use the intersecting diagonals prop...   \n",
       "4  substitute positive integer values into formul...   \n",
       "\n",
       "                                  misconception_text  misconception_id  label  \\\n",
       "0  Confuses the order of operations, believes add...              1672      0   \n",
       "1  Does not know that to factorise a quadratic ex...              2142      0   \n",
       "2  Believes if you add the same value to all numb...              1073      0   \n",
       "3        Does not know the properties of a rectangle              1180      0   \n",
       "4  Thinks you can find missing values in a given ...              1818      0   \n",
       "\n",
       "   qlength  mlength  \n",
       "0      175       80  \n",
       "1      126      167  \n",
       "2      378       86  \n",
       "3      348       43  \n",
       "4      324      146  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(next_sentence_df.shape)\n",
    "\n",
    "next_sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "next_sentence_df.plot(x='qlength', kind='bar')\n",
    "plt.title('sentence lengths')\n",
    "plt.xlabel('Question Length')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T20:21:37.152716Z",
     "iopub.status.busy": "2024-11-30T20:21:37.152282Z",
     "iopub.status.idle": "2024-11-30T20:26:04.022094Z",
     "shell.execute_reply": "2024-11-30T20:26:04.020697Z",
     "shell.execute_reply.started": "2024-11-30T20:21:37.152680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length 1353\n",
      "max question use a linear sequence expressed as a pattern to make a prediction about another term in the sequence other than the next one tom and katie are discussing this sequence the first 3 patterns in a sequence are shown the first pattern is a blue rectangle with 6 yellow circles attached to its perimeter 2 circles on each of the longer sides and 1 circle on each of the shorter sides pattern 2 is made up of 2 blue rectangles attached together in a row by their short edges there are also 10 yellow circles in this pattern attached to the perimeter of the rectangles 2 circles on every longer side of each rectangle and 1 circle on each of the two free shorter sides ie that are not attached to the other rectangle pattern 3 is made up of 3 blue rectangles attached together in a row by their short edges there are also 14 yellow circles in this pattern attached to the perimeter of the rectangles 2 circles on every longer side of each rectangle and 1 circle on each of the two free shorter sides ie that are not attached to another rectangle tom says the number of circles in the \\ 10^{\\text {th }} \\ term will be double the number of circles in the \\ 5^{\\text {th }} \\ term katie says the number of rectangles in the \\ 10^{\\text {th }} \\ term will be double the number of rectangles in the \\ 5^{\\text {th }} \\ term who do you agree with both tom and katie\n",
      "max misconception \n"
     ]
    }
   ],
   "source": [
    "sentence_a = []\n",
    "sentence_b = []\n",
    "sentence_label = []\n",
    "max_sentence_length = 0\n",
    "max_question = ''\n",
    "max_misconception = ''\n",
    "for index, row in next_sentence_df.iterrows():\n",
    "    if (len(row['problem_and_wrong_answer']) > max_sentence_length):\n",
    "        max_sentence_length = len(row['problem_and_wrong_answer'])\n",
    "        max_question = row['problem_and_wrong_answer']\n",
    "    sentence_a.append(row['problem_and_wrong_answer'])\n",
    "    misconception_id = row['misconception_id']\n",
    "    if (len(row['misconception_text']) > max_sentence_length):\n",
    "        max_sentence_length = len(row['misconception_text'])\n",
    "        max_misconception = row['misconception_text']\n",
    "    sentence_b.append(row['misconception_text'])\n",
    "    sentence_label.append(row['label'])\n",
    "    #print(f\"Index: {index}, problem_and_wrong_answer: {row['problem_and_wrong_answer']}\")\n",
    "\n",
    "print(\"max sentence length\", max_sentence_length)\n",
    "print('max question', max_question)\n",
    "print('max misconception', max_misconception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://towardsdatascience.com/how-to-fine-tune-bert-with-nsp-8b5615468e12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://keras.io/examples/nlp/pretraining_BERT/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T20:02:40.111333Z",
     "iopub.status.busy": "2024-11-30T20:02:40.110398Z",
     "iopub.status.idle": "2024-11-30T20:02:56.476391Z",
     "shell.execute_reply": "2024-11-30T20:02:56.475333Z",
     "shell.execute_reply.started": "2024-11-30T20:02:40.111293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import re\n",
    "import random\n",
    "import transformers, datasets\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizer\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_BATCH_SIZE = 256  # Batch-size to train the tokenizer on\n",
    "TOKENIZER_VOCABULARY = 25000  # Total number of unique subwords the tokenizer can have\n",
    "\n",
    "BLOCK_SIZE = 128  # Maximum number of tokens in an input sample\n",
    "NSP_PROB = 0.50  # Probability that the next sentence is the actual next sentence in NSP\n",
    "SHORT_SEQ_PROB = 0.1  # Probability of generating shorter sequences to minimize the mismatch between pretraining and fine-tuning.\n",
    "MAX_LENGTH = 512  # Maximum number of tokens in an input sample after padding\n",
    "\n",
    "MLM_PROB = 0.2  # Probability with which tokens are masked in MLM\n",
    "\n",
    "TRAIN_BATCH_SIZE = 2  # Batch-size for pretraining the model on\n",
    "MAX_EPOCHS = 1  # Maximum number of epochs to train the model for\n",
    "LEARNING_RATE = 1e-4  # Learning rate for training the model\n",
    "\n",
    "MODEL_CHECKPOINT = \"bert-base-cased\"  # Name of pretrained model from  Model Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are importing a pre-trained BERT tokenizer and a BERT model with an MLM head from the Hugging Face repository.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T20:03:55.313165Z",
     "iopub.status.busy": "2024-11-30T20:03:55.312329Z",
     "iopub.status.idle": "2024-11-30T20:03:59.234263Z",
     "shell.execute_reply": "2024-11-30T20:03:59.232821Z",
     "shell.execute_reply.started": "2024-11-30T20:03:55.313121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "#model = AutoModel.from_pretrained(\"google-bert/bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the Wordpiece tokenizer used for fine-tuning is BertTokenizer. The model used is TFBertForMaskedLM, a BERT model with an MLM head that can accept only Tensorflow tensors. In both of them, the check-point used is bert-base-uncased. Lets look at the model summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-30T20:04:58.252769Z",
     "iopub.status.busy": "2024-11-30T20:04:58.252359Z",
     "iopub.status.idle": "2024-11-30T20:04:58.291153Z",
     "shell.execute_reply": "2024-11-30T20:04:58.289997Z",
     "shell.execute_reply.started": "2024-11-30T20:04:58.252732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/data-and-beyond/complete-guide-to-building-bert-model-from-sratch-3e6562228891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordPiece Tokenization\n",
    "\n",
    "The initial stage of creating a fresh BERT model involves training a new tokenizer. Tokenization is the process of breaking down a text into smaller units called tokens, which are then converted into a numerical representation. An example of this would be splitting the sentence\n",
    "\n",
    " I like surfboarding!  [[CLS], i, like, surf, ##board, ##ing, !, [SEP]]  [1, 48, 250, 4033, 3588, 154, 5, 2]\n",
    "A tokenized BERT input always starts with a special [CLS] token and ends with a special [SEP] token, which are used for specific purposes that will be explained later. BERT employs a WordPiece tokenizer, which can split a single word into multiple tokens. For instance, in the example given earlier, the word surfboarding is broken down into ['surf', '##boarding', '##ing']. This technique helps the model to understand that words like surfboardand snowboardhave shared meaning through the common wordpiece ##board. By referring to the explanation from HuggingFace, WordPiece computes a score for each pair, using the following\n",
    "\n",
    "score = (freq_of_pair) / (freq_of_first_element  freq_of_second_element)\n",
    "\n",
    "By dividing the frequency of the pair by the product of the frequencies of each of its parts, the algorithm prioritizes the merging of pairs where the individual parts are less frequent in the vocabulary. For instance, it wont necessarily merge (\"un\", \"##able\") even if that pair occurs very frequently in the vocabulary, because the two pairs \"un\" and \"##able\" will likely each appear in a lot of other words and have a high frequency. In contrast, a pair like (\"hu\", \"##gging\") will probably be merged faster (assuming the word hugging appears often in the vocabulary) since \"hu\" and \"##gging\" are likely to be less frequent individually.\n",
    "\n",
    "To train the tokenizer, the BertWordPieceTokenizer from the transformer library was used with the steps below:\n",
    "\n",
    "1. Saving the conversation text into multiple .txt files (with batch of N=10000)\n",
    "2. Define BertWordPieceTokenizer with some parameters likeclean_text to remove control characters, handle_chinese_chars to include spaces around Chinese characters, stripe_accents to remove accents and make   e,   o, andlowercase to view capital and lowercase characters as equal.\n",
    "3. Train the tokenizer based on the file path to .txt files with parameters like vocab_size defines the total number of tokens, min_frequency for minimum frequency for a pair of tokens to be merged, special_tokens defines a list of the special tokens that BERT uses, limit_alphabet for a maximum number of different characters, workpieces_prefix the prefix added to pieces of words (like ##ing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory exists ./data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1406/1406 [00:00<00:00, 468849.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory exists ./bert-it-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\billl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:2110: FutureWarning: Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated and won't be possible anymore in v5. Use a model identifier or the path to a directory instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# WordPiece tokenizer\n",
    "import tqdm\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "### save data as txt file\n",
    "data_dir = './data'\n",
    "if os.path.isdir(data_dir):\n",
    "    print('directory exists',data_dir)\n",
    "else:\n",
    "    os.mkdir(data_dir)\n",
    "text_data = []\n",
    "file_count = 0\n",
    "\n",
    "for sample in tqdm.tqdm([x[0] for x in pairs]):\n",
    "    text_data.append(sample)\n",
    "\n",
    "    # once we hit the 10K mark, save to file\n",
    "    if len(text_data) == 10000:\n",
    "        with open(f'./data/text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "            fp.write('\\n'.join(text_data))\n",
    "        text_data = []\n",
    "        file_count += 1\n",
    "\n",
    "paths = [str(x) for x in Path('./data').glob('**/*.txt')]\n",
    "\n",
    "### training own tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=False,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "tokenizer.train( \n",
    "    files=paths,\n",
    "    vocab_size=30_000, \n",
    "    min_frequency=5,\n",
    "    limit_alphabet=1000, \n",
    "    wordpieces_prefix='##',\n",
    "    special_tokens=['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]']\n",
    "    )\n",
    "\n",
    "bert_it_dir = './bert-it-1'\n",
    "if os.path.isdir(bert_it_dir):\n",
    "    print('directory exists',bert_it_dir)\n",
    "else:\n",
    "    os.mkdir(bert_it_dir)\n",
    "\n",
    "tokenizer.save_model(bert_it_dir, 'bert-it')\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-it-1/bert-it-vocab.txt', local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import itertools\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data_pair, tokenizer, seq_len=64):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = seq_len\n",
    "        self.corpus_lines = len(data_pair)\n",
    "        self.lines = data_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.corpus_lines\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "\n",
    "        # Step 1: get random sentence pair, either negative or positive (saved as is_next_label)\n",
    "        t1, t2, is_next_label = self.get_sent(item)\n",
    "\n",
    "        # Step 2: replace random words in sentence with mask / random words\n",
    "        t1_random, t1_label = self.random_word(t1)\n",
    "        t2_random, t2_label = self.random_word(t2)\n",
    "\n",
    "        # Step 3: Adding CLS and SEP tokens to the start and end of sentences\n",
    "         # Adding PAD token for labels\n",
    "        t1 = [self.tokenizer.vocab['[CLS]']] + t1_random + [self.tokenizer.vocab['[SEP]']]\n",
    "        t2 = t2_random + [self.tokenizer.vocab['[SEP]']]\n",
    "        t1_label = [self.tokenizer.vocab['[PAD]']] + t1_label + [self.tokenizer.vocab['[PAD]']]\n",
    "        t2_label = t2_label + [self.tokenizer.vocab['[PAD]']]\n",
    "\n",
    "        # Step 4: combine sentence 1 and 2 as one input\n",
    "        # adding PAD tokens to make the sentence same length as seq_len\n",
    "        segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n",
    "        bert_input = (t1 + t2)[:self.seq_len]\n",
    "        bert_label = (t1_label + t2_label)[:self.seq_len]\n",
    "        padding = [self.tokenizer.vocab['[PAD]'] for _ in range(self.seq_len - len(bert_input))]\n",
    "        bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n",
    "\n",
    "        output = {\"bert_input\": bert_input,\n",
    "                  \"bert_label\": bert_label,\n",
    "                  \"segment_label\": segment_label,\n",
    "                  \"is_next\": is_next_label}\n",
    "\n",
    "        return {key: torch.tensor(value) for key, value in output.items()}\n",
    "\n",
    "    def random_word(self, sentence):\n",
    "        tokens = sentence.split()\n",
    "        output_label = []\n",
    "        output = []\n",
    "\n",
    "        # 15% of the tokens would be replaced\n",
    "        for i, token in enumerate(tokens):\n",
    "            prob = random.random()\n",
    "\n",
    "            # remove cls and sep token\n",
    "            token_id = self.tokenizer(token)['input_ids'][1:-1]\n",
    "\n",
    "            if prob < 0.15:\n",
    "                prob /= 0.15\n",
    "\n",
    "                # 80% chance change token to mask token\n",
    "                if prob < 0.8:\n",
    "                    for i in range(len(token_id)):\n",
    "                        output.append(self.tokenizer.vocab['[MASK]'])\n",
    "\n",
    "                # 10% chance change token to random token\n",
    "                elif prob < 0.9:\n",
    "                    for i in range(len(token_id)):\n",
    "                        output.append(random.randrange(len(self.tokenizer.vocab)))\n",
    "\n",
    "                # 10% chance change token to current token\n",
    "                else:\n",
    "                    output.append(token_id)\n",
    "\n",
    "                output_label.append(token_id)\n",
    "\n",
    "            else:\n",
    "                output.append(token_id)\n",
    "                for i in range(len(token_id)):\n",
    "                    output_label.append(0)\n",
    "\n",
    "        # flattening\n",
    "        output = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output]))\n",
    "        output_label = list(itertools.chain(*[[x] if not isinstance(x, list) else x for x in output_label]))\n",
    "        assert len(output) == len(output_label)\n",
    "        return output, output_label\n",
    "\n",
    "    def get_sent(self, index):\n",
    "        '''return random sentence pair'''\n",
    "        t1, t2 = self.get_corpus_line(index)\n",
    "\n",
    "        # negative or positive pair, for next sentence prediction\n",
    "        if random.random() > 0.5:\n",
    "            return t1, t2, 1\n",
    "        else:\n",
    "            return t1, self.get_random_line(), 0\n",
    "\n",
    "    def get_corpus_line(self, item):\n",
    "        '''return sentence pair'''\n",
    "        return self.lines[item][0], self.lines[item][1]\n",
    "\n",
    "    def get_random_line(self):\n",
    "        '''return random single sentence'''\n",
    "        return self.lines[random.randrange(len(self.lines))][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406\n",
      "{'bert_input': tensor([1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4,\n",
      "        4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 3, 2, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 3, 3, 4, 4, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'bert_label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0,\n",
      "        0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4, 0, 0, 4, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'segment_label': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), 'is_next': tensor(1)}\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 128\n",
    "train_data = BERTDataset(\n",
    "   pairs, seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "print(len(train_data))\n",
    "train_loader = DataLoader(\n",
    "   train_data, batch_size=32, shuffle=True, pin_memory=True)\n",
    "sample_data = next(iter(train_loader))\n",
    "print(train_data[random.randrange(len(train_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "The embedding in BERT comprises of three parts, mainly the token embeddings, segment embeddings and position embeddings.\n",
    "\n",
    "\n",
    "In NLP model, the order of the words and their position in a sentence matters and the meaning of the entire sentence can change if the words are re-ordered. As such, transformer model did a position embedding for each token in the input using the formula\n",
    "\n",
    "\n",
    "where\n",
    "\n",
    "  - k: Position of an object in input sequence, 0 < k < L/2\n",
    "  - d: Dimension of the output embedding space\n",
    "  - n: User defined scalar. Default by 10,000\n",
    "  - i: Used for mapping to column indices 0 < i < d/2. A single value of i maps to both sine and cosine functions\n",
    "\n",
    "For all three different type of embeddings, they must be in the similar output size (768 in this case), so that all three of them can be summed together to be a single embedded output. You may notice thepadding_idx is specified as 0, this is to make pad token remains as 0 and not being updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=128):\n",
    "        super().__init__()\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        for pos in range(max_len):   \n",
    "            # for each dimension of the each position\n",
    "            for i in range(0, d_model, 2):   \n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "\n",
    "        # include the batch size\n",
    "        self.pe = pe.unsqueeze(0)   \n",
    "        # self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe\n",
    "\n",
    "class BERTEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Embedding which is consisted with under features\n",
    "        1. TokenEmbedding : normal embedding matrix\n",
    "        2. PositionalEmbedding : adding positional information using sin, cos\n",
    "        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)\n",
    "        sum of all these features are output of BERTEmbedding\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_size, seq_len=max_seq_len, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param vocab_size: total vocab size\n",
    "        :param embed_size: embedding size of token embedding\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        # (m, seq_len) --> (m, seq_len, embed_size)\n",
    "        # padding_idx is not updated during training, remains as fixed pad (0)\n",
    "        self.token = torch.nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.segment = torch.nn.Embedding(3, embed_size, padding_idx=0)\n",
    "        self.position = PositionalEmbedding(d_model=embed_size, max_len=seq_len)\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "       \n",
    "    def forward(self, sequence, segment_label):\n",
    "        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Head Attention\n",
    "A basic Transformer consists of an encoder to read the text input and a decoder to produce a prediction for the task. Since BERTs goal is to generate a language representation model, it only needs the encoder part. The code snippet for Multi-head attention might looks complicated at first sight, but it is just a simple translation from the equation below\n",
    "\n",
    "$\n",
    "Z = Softmax(\\frac{QK^T}{\\sqrt{d_k}})V\n",
    "$\n",
    "\n",
    "where Q, K, V are identical and linear transformation of input embeddings. The one thing that need more attention is the shape of input tensor, therefore, .permute() function is applied to amend the shape of tensor to fulfil the requirement for dot product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The details of the class MultiHeadedAttention\n",
    "\n",
    "* Its called multi-head attention because the hidden size: d_model(768) is split by heads(12), this allows the model to jointly attend to information at different positions from different representational spaces.\n",
    "* It takes the query, key, and value as inputs, and the size is permuted from (batch_size, max_len, hidden_size)  (batch_size, num_heads, max_len, hidden_size / num_heads ). This indicates that all the 3 inpurs are linearly projected from the d_model dimensional space to heads sets of d_k dimensional vectors.\n",
    "* Attention score matrix is computed using matrix multiplication between the query(Q) and key(K) tensors, followed by scaling by the square root of the key tensors dimension\n",
    "* The mask is applied to the attention matrix and filled with -1e9 (close to negative infinity). This is done because the large negative inputs to softmax are near zero in the output.\n",
    "* The final output is a weighted sum of the value(V) tensors, where the weights are determined by the softmax of the scaled dot-product between the query and key vectors.\n",
    "\n",
    "### The EncoderLayer class contains 2 sublayers:.\n",
    "\n",
    "* MultiHeadedAttention: A multi-headed self-attention module that computes the attention weights between each element in the input sequence\n",
    "* FeedForward: A feedforward network with one hidden layer that applies a non-linear activation function (GELU) to the output of the first linear layer and produces a d_model dimensional output.\n",
    "\n",
    "Each of these sublayers has a residual connection around it followed by a layer normalization LayerNorm(x + Sublayer(x)). Residual connections help in avoiding the vanishing gradient problem in deep networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "### attention layers\n",
    "class MultiHeadedAttention(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, heads, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        \n",
    "        assert d_model % heads == 0\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.query = torch.nn.Linear(d_model, d_model)\n",
    "        self.key = torch.nn.Linear(d_model, d_model)\n",
    "        self.value = torch.nn.Linear(d_model, d_model)\n",
    "        self.output_linear = torch.nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, query, key, value, mask):\n",
    "        \"\"\"\n",
    "        query, key, value of shape: (batch_size, max_len, d_model)\n",
    "        mask of shape: (batch_size, 1, 1, max_words)\n",
    "        \"\"\"\n",
    "        # (batch_size, max_len, d_model)\n",
    "        query = self.query(query)\n",
    "        key = self.key(key)        \n",
    "        value = self.value(value)   \n",
    "        \n",
    "        # (batch_size, max_len, d_model) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)   \n",
    "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
    "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
    "        \n",
    "        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
    "        scores = torch.matmul(query, key.permute(0, 1, 3, 2)) / math.sqrt(query.size(-1))\n",
    "\n",
    "        # fill 0 mask with super small number so it wont affect the softmax weight\n",
    "        # (batch_size, h, max_len, max_len)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)    \n",
    "\n",
    "        # (batch_size, h, max_len, max_len)\n",
    "        # softmax to put attention weight for all non-pad tokens\n",
    "        # max_len X max_len matrix of attention\n",
    "        weights = F.softmax(scores, dim=-1)           \n",
    "        weights = self.dropout(weights)\n",
    "\n",
    "        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        context = torch.matmul(weights, value)\n",
    "\n",
    "        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, d_model)\n",
    "        context = context.permute(0, 2, 1, 3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
    "\n",
    "        # (batch_size, max_len, d_model)\n",
    "        return self.output_linear(context)\n",
    "\n",
    "class FeedForward(torch.nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, middle_dim=2048, dropout=0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = torch.nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.activation = torch.nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out\n",
    "\n",
    "class EncoderLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        d_model=768,\n",
    "        heads=12, \n",
    "        feed_forward_hidden=768 * 4, \n",
    "        dropout=0.1\n",
    "        ):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.layernorm = torch.nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadedAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model, middle_dim=feed_forward_hidden)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, embeddings, mask):\n",
    "        # embeddings: (batch_size, max_len, d_model)\n",
    "        # encoder mask: (batch_size, 1, 1, max_len)\n",
    "        # result: (batch_size, max_len, d_model)\n",
    "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
    "        # residual layer\n",
    "        interacted = self.layernorm(interacted + embeddings)\n",
    "        # bottleneck\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        encoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final BERT Model\n",
    "Coming next, we are going to incorporate the encoder layer with attention mechanism into the final BERTs construction.\n",
    "\n",
    "1. The BERT class initializes the embedding layer for the input sequence, as well as multi layers of EncoderLayer blocks. The forward method of this class takes in the input sequence and a segment info tensor, applies attention masking to the input(for padded token), embeds the input sequence, and then passes it through the encoder blocks to obtain the output.\n",
    "2. The NextSentencePrediction class is a 2-class classification model that takes in the output of the BERT class and predicts whether the input sequence contains two consecutive sentences or not. The forward method applies applies linear transformation and log softmax function to obtain the predicted probabilities of the two classes.\n",
    "3. The MaskedLanguageModel class is a multi-class classification model that takes in the output of the BERT class and predicts the original tokens for the masked input sequence. The forward method applies a linear transformation and log softmax function to obtain the predicted probabilities of each token in the vocabulary.\n",
    "4. The BERTLM class combines the BERT, NextSentencePrediction, and MaskedLanguageModel classes to create a complete BERT language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    BERT model : Bidirectional Encoder Representations from Transformers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, d_model=768, n_layers=12, heads=12, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param vocab_size: vocab_size of total words\n",
    "        :param hidden: BERT model hidden size\n",
    "        :param n_layers: numbers of Transformer blocks(layers)\n",
    "        :param attn_heads: number of attention heads\n",
    "        :param dropout: dropout rate\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "        self.heads = heads\n",
    "\n",
    "        # paper noted they used 4 * hidden_size for ff_network_hidden_size\n",
    "        self.feed_forward_hidden = d_model * 4\n",
    "\n",
    "        # embedding for BERT, sum of positional, segment, token embeddings\n",
    "        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=d_model)\n",
    "\n",
    "        # multi-layers transformer blocks, deep network\n",
    "        self.encoder_blocks = torch.nn.ModuleList(\n",
    "            [EncoderLayer(d_model, heads, d_model * 4, dropout) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x, segment_info):\n",
    "        # attention masking for padded token\n",
    "        # (batch_size, 1, seq_len, seq_len)\n",
    "        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
    "\n",
    "        # embedding the indexed sequence to sequence of vectors\n",
    "        x = self.embedding(x, segment_info)\n",
    "\n",
    "        # running over multiple transformer blocks\n",
    "        for encoder in self.encoder_blocks:\n",
    "            x = encoder.forward(x, mask)\n",
    "        return x\n",
    "\n",
    "class NextSentencePrediction(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    2-class classification model : is_next, is_not_next\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden):\n",
    "        \"\"\"\n",
    "        :param hidden: BERT model output size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(hidden, 2)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # use only the first token which is the [CLS]\n",
    "        return self.softmax(self.linear(x[:, 0]))\n",
    "\n",
    "class MaskedLanguageModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    predicting origin token from masked input sequence\n",
    "    n-class classification problem, n-class = vocab_size\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden, vocab_size):\n",
    "        \"\"\"\n",
    "        :param hidden: output size of BERT model\n",
    "        :param vocab_size: total vocab size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(hidden, vocab_size)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x))\n",
    "\n",
    "class BERTLM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    BERT Language Model\n",
    "    Next Sentence Prediction Model + Masked Language Model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert: BERT, vocab_size):\n",
    "        \"\"\"\n",
    "        :param bert: BERT model which should be trained\n",
    "        :param vocab_size: total vocab size for masked_lm\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.next_sentence = NextSentencePrediction(self.bert.d_model)\n",
    "        self.mask_lm = MaskedLanguageModel(self.bert.d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, segment_label):\n",
    "        x = self.bert(x, segment_label)\n",
    "        return self.next_sentence(x), self.mask_lm(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer\n",
    "The original BERT model was trained using Adam optimizer with a custom learning rate scheduler according to the formula in the paper.\n",
    "\n",
    "$\n",
    "lrate = d^{-0.5}_{model} * min(step\\_num^{-0.5},step\\_num * warmup\\_steps^{-1.5})\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "\n",
    "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(d_model, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "We came a long way to finally combine what we have discussed above and start training a new BERT model.\n",
    "\n",
    "The BERTTrainerclass contains train() and test() methods that call the iteration() method to iterate over the given dataloader (train or test) for a specified epoch. The iteration() method calculates the loss and accuracy of the model on the given data and updates the parameters using backpropagation and optimization. It also logs the progress of training with a progress bar and prints the average loss and accuracy at the end of each epoch. Finally, we can do a test run for the BERT model on the processed data with low number of epochs count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTTrainer:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        train_dataloader, \n",
    "        test_dataloader=None, \n",
    "        lr= 1e-4,\n",
    "        weight_decay=0.01,\n",
    "        betas=(0.9, 0.999),\n",
    "        warmup_steps=10000,\n",
    "        log_freq=10,\n",
    "        device='cuda'\n",
    "        \n",
    "        ):\n",
    "        self.losses = []\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.train_data = train_dataloader\n",
    "        self.test_data = test_dataloader\n",
    "\n",
    "        # Setting the Adam optimizer with hyper-param\n",
    "        self.optim = Adam(self.model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "        self.optim_schedule = ScheduledOptim(\n",
    "            self.optim, self.model.bert.d_model, n_warmup_steps=warmup_steps\n",
    "            )\n",
    "\n",
    "        # Using Negative Log Likelihood Loss function for predicting the masked_token\n",
    "        self.criterion = torch.nn.NLLLoss(ignore_index=0)\n",
    "        self.log_freq = log_freq\n",
    "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
    "    \n",
    "    def train(self, epoch):\n",
    "        self.iteration(epoch, self.train_data)\n",
    "\n",
    "    def test(self, epoch):\n",
    "        self.iteration(epoch, self.test_data, train=False)\n",
    "\n",
    "    def get_losses (self):\n",
    "        return self.losses\n",
    "    \n",
    "    def iteration(self, epoch, data_loader, train=True):\n",
    "        \n",
    "        avg_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_element = 0\n",
    "        \n",
    "        mode = \"train\" if train else \"test\"\n",
    "\n",
    "        # progress bar\n",
    "        data_iter = tqdm.tqdm(\n",
    "            enumerate(data_loader),\n",
    "            desc=\"EP_%s:%d\" % (mode, epoch),\n",
    "            total=len(data_loader),\n",
    "            bar_format=\"{l_bar}{r_bar}\"\n",
    "        )\n",
    "\n",
    "        for i, data in data_iter:\n",
    "\n",
    "            # 0. batch_data will be sent into the device(GPU or cpu)\n",
    "            data = {key: value.to(self.device) for key, value in data.items()}\n",
    "\n",
    "            # 1. forward the next_sentence_prediction and masked_lm model\n",
    "            next_sent_output, mask_lm_output = self.model.forward(data[\"bert_input\"], data[\"segment_label\"])\n",
    "\n",
    "            # 2-1. NLL(negative log likelihood) loss of is_next classification result\n",
    "            next_loss = self.criterion(next_sent_output, data[\"is_next\"])\n",
    "\n",
    "            # 2-2. NLLLoss of predicting masked token word\n",
    "            # transpose to (m, vocab_size, seq_len) vs (m, seq_len)\n",
    "            # criterion(mask_lm_output.view(-1, mask_lm_output.size(-1)), data[\"bert_label\"].view(-1))\n",
    "            mask_loss = self.criterion(mask_lm_output.transpose(1, 2), data[\"bert_label\"])\n",
    "\n",
    "            # 2-3. Adding next_loss and mask_loss : 3.4 Pre-training Procedure\n",
    "            loss = next_loss + mask_loss\n",
    "\n",
    "            # 3. backward and optimization only in train\n",
    "            if train:\n",
    "                self.optim_schedule.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim_schedule.step_and_update_lr()\n",
    "\n",
    "            # next sentence prediction accuracy\n",
    "            correct = next_sent_output.argmax(dim=-1).eq(data[\"is_next\"]).sum().item()\n",
    "            avg_loss += loss.item()\n",
    "            total_correct += correct\n",
    "            total_element += data[\"is_next\"].nelement()\n",
    "\n",
    "            post_fix = {\n",
    "                \"epoch\": epoch,\n",
    "                \"iter\": i,\n",
    "                \"avg_loss\": avg_loss / (i + 1),\n",
    "                \"avg_acc\": total_correct / total_element * 100,\n",
    "                \"loss\": loss.item()\n",
    "            }\n",
    "            self.losses.append(post_fix)\n",
    "            if i % self.log_freq == 0:\n",
    "                data_iter.write(str(post_fix))\n",
    "        print(\n",
    "            f\"EP{epoch}, {mode}: \\\n",
    "            avg_loss={avg_loss / len(data_iter)}, \\\n",
    "            total_acc={total_correct * 100.0 / total_element}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 14184199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002BFE1B702E0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''training run'''\n",
    "\n",
    "train_data = BERTDataset(\n",
    "   pairs, seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "   train_data, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "val_data = BERTDataset(\n",
    "   val_pairs, seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "   val_data, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "\n",
    "\n",
    "bert_model = BERT(\n",
    "  vocab_size=len(tokenizer.vocab),\n",
    "  d_model=768,\n",
    "  n_layers=2,\n",
    "  heads=12,\n",
    "  dropout=0.1\n",
    ")\n",
    "\n",
    "bert_lm = BERTLM(bert_model, len(tokenizer.vocab))\n",
    "outputs = []\n",
    "bert_trainer = BERTTrainer(model=bert_lm, train_dataloader=train_loader, test_dataloader=val_loader, device='cpu')\n",
    "# do just one epic so we can get the flow of getting parameters, running training and validation and graphing loss\n",
    "epochs = 10\n",
    "\n",
    "if (train_model): \n",
    "   for epoch in range(epochs):\n",
    "      bert_trainer.train(epoch)\n",
    "\n",
    "bert_trainer.model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.BERTTrainer object at 0x000002BFD68D2240>\n",
      "\n",
      "\n",
      "Model params:\n",
      "Model's state_dict:\n",
      "embedding.token.weight \t torch.Size([5, 768])\n",
      "embedding.segment.weight \t torch.Size([3, 768])\n",
      "encoder_blocks.0.layernorm.weight \t torch.Size([768])\n",
      "encoder_blocks.0.layernorm.bias \t torch.Size([768])\n",
      "encoder_blocks.0.self_multihead.query.weight \t torch.Size([768, 768])\n",
      "encoder_blocks.0.self_multihead.query.bias \t torch.Size([768])\n",
      "encoder_blocks.0.self_multihead.key.weight \t torch.Size([768, 768])\n",
      "encoder_blocks.0.self_multihead.key.bias \t torch.Size([768])\n",
      "encoder_blocks.0.self_multihead.value.weight \t torch.Size([768, 768])\n",
      "encoder_blocks.0.self_multihead.value.bias \t torch.Size([768])\n",
      "encoder_blocks.0.self_multihead.output_linear.weight \t torch.Size([768, 768])\n",
      "encoder_blocks.0.self_multihead.output_linear.bias \t torch.Size([768])\n",
      "encoder_blocks.0.feed_forward.fc1.weight \t torch.Size([3072, 768])\n",
      "encoder_blocks.0.feed_forward.fc1.bias \t torch.Size([3072])\n",
      "encoder_blocks.0.feed_forward.fc2.weight \t torch.Size([768, 3072])\n",
      "encoder_blocks.0.feed_forward.fc2.bias \t torch.Size([768])\n",
      "encoder_blocks.1.layernorm.weight \t torch.Size([768])\n",
      "encoder_blocks.1.layernorm.bias \t torch.Size([768])\n",
      "encoder_blocks.1.self_multihead.query.weight \t torch.Size([768, 768])\n",
      "encoder_blocks.1.self_multihead.query.bias \t torch.Size([768])\n",
      "encoder_blocks.1.self_multihead.key.weight \t torch.Size([768, 768])\n",
      "encoder_blocks.1.self_multihead.key.bias \t torch.Size([768])\n",
      "encoder_blocks.1.self_multihead.value.weight \t torch.Size([768, 768])\n",
      "encoder_blocks.1.self_multihead.value.bias \t torch.Size([768])\n",
      "encoder_blocks.1.self_multihead.output_linear.weight \t torch.Size([768, 768])\n",
      "encoder_blocks.1.self_multihead.output_linear.bias \t torch.Size([768])\n",
      "encoder_blocks.1.feed_forward.fc1.weight \t torch.Size([3072, 768])\n",
      "encoder_blocks.1.feed_forward.fc1.bias \t torch.Size([3072])\n",
      "encoder_blocks.1.feed_forward.fc2.weight \t torch.Size([768, 3072])\n",
      "encoder_blocks.1.feed_forward.fc2.bias \t torch.Size([768])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.01, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]}]\n"
     ]
    }
   ],
   "source": [
    "print(bert_trainer)\n",
    "\n",
    "if (train_model):\n",
    "  for epoch in range(epochs):\n",
    "    bert_trainer.test(epoch)\n",
    "\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in bert_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", bert_model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in bert_trainer.optim.state_dict():\n",
    "    print(var_name, \"\\t\", bert_trainer.optim.state_dict()[var_name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (train_model):\n",
    "    torch.save(bert_lm,'eedi_mining_bert.pth')\n",
    "    torch.save(bert_lm.state_dict(), 'eedi_mining_bert_dict.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billl\\AppData\\Local\\Temp\\ipykernel_10504\\2544680678.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('eedi_mining_bert.pth')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NextSentencePrediction.forward() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meedi_mining_bert.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# AutoModelForSequenceClassification.from_pretrained('path/to/checkpoint')\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mbert_lm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mTypeError\u001b[0m: NextSentencePrediction.forward() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = torch.load('eedi_mining_bert.pth')\n",
    "# AutoModelForSequenceClassification.from_pretrained('path/to/checkpoint')\n",
    "bert_lm.next_sentence()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9738540,
     "sourceId": 82695,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
